\documentclass[a4paper]{paper}

% Packages
\usepackage{mathtools}
\usepackage{etoolbox}
\usepackage{amsfonts,mathrsfs}
%\usepackage{tikz-cd}
\usepackage[matrix,arrow]{xy}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{hyperref} 
\hypersetup{%
    bookmarks=true,         % show bookmarks bar?
    pdfmenubar=true,       % show Acrobat's menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links
    citecolor=red,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan,           % color of external links
    pdfborder = {0,0,0}
}

\usepackage{acro}
\usepackage{cleveref}
\usepackage{extraenv}
\usepackage{todonotes}
\usepackage{float}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{nicefrac}



% Own definitions


% Spaces
\newcommand*{\SPC}[1]{{\ensuremath{\mathscr{#1}}}}
\newcommand*{\SPCL}{\SPC{L}}
\newcommand*{\SPCX}{\SPC{X}}
\newcommand*{\SPCY}{\SPC{Y}}
\newcommand*{\SPCZ}{\SPC{Z}}

\newcommand*{\LINOP}[2]{{L(#1, #2)}}
\newcommand*{\BLINOP}[2]{{\SPCL(#1, #2)}}
\newcommand*{\LEBES}[2]{\ensuremath{L^{#1}\left( #2 \right)}}

\newcommand*{\FIELD}{{\ensuremath{\mathbb{F}}}}
\newcommand*{\Fn}{{\ensuremath{\FIELD^n}}}
\newcommand*{\Fm}{{\ensuremath{\FIELD^m}}}
\newcommand*{\Fk}{{\ensuremath{\FIELD^k}}}
\newcommand*{\Fmxn}{{\ensuremath{\FIELD^{m \times n}}}}
\newcommand*{\Fnxn}{{\ensuremath{\FIELD^{n \times n}}}}
\newcommand*{\Fmxm}{{\ensuremath{\FIELD^{m \times m}}}}

\newcommand{\RR}{{\ensuremath{\mathbb{R}}}}
\newcommand{\CC}{{\ensuremath{\mathbb{C}}}}
\newcommand{\NN}{{\ensuremath{\mathbb{N}}}}
\newcommand{\ZZ}{{\ensuremath{\mathbb{Z}}}}


% Operators
\newcommand*{\OP}[1]{{\ensuremath{\mathcal{#1}}}}
\newcommand*{\OPM}{\OP{M}}
\newcommand*{\OPP}{\OP{P}}
\newcommand*{\OPT}{\OP{T}}
\newcommand*{\OPU}{\OP{U}}
\newcommand*{\OPID}{\OP{\mathrm{Id}}}

\newcommand{\DISCOP}[1]{{\ensuremath{\mathsf{#1}}}}
\newcommand*{\DISCOPT}{\DISCOP{T}}
\newcommand*{\DISCOPU}{\DISCOP{U}}
\newcommand*{\DISCOPID}{\DISCOP{\mathrm{Id}}}

\newcommand*{\EXT}[2]{\ensuremath{E_{#1}^{#2}}}
\newcommand*{\REST}[2]{\ensuremath{R_{#1}^{#2}}}
\newcommand*{\PROJ}[2]{\ensuremath{P_{#1}^{#2}}}
\newcommand*{\COPROJ}[2]{\ensuremath{Q_{#1}^{#2}}}
\newcommand*{\RnX}{{\ensuremath{\REST{n}{\SPC{X}}}}}
\newcommand*{\RmX}{{\ensuremath{\REST{m}{\SPC{X}}}}}
\newcommand*{\RnY}{{\ensuremath{\REST{n}{\SPC{Y}}}}}
\newcommand*{\RmY}{{\ensuremath{\REST{m}{\SPC{Y}}}}}
\newcommand*{\EnX}{{\ensuremath{\EXT{n}{\SPC{X}}}}}
\newcommand*{\EmX}{{\ensuremath{\EXT{m}{\SPC{X}}}}}
\newcommand*{\EnY}{{\ensuremath{\EXT{n}{\SPC{Y}}}}}
\newcommand*{\EmY}{{\ensuremath{\EXT{m}{\SPC{Y}}}}}
\newcommand*{\PnX}{{\ensuremath{\PROJ{n}{\SPCX}}}}
\newcommand*{\PmY}{{\ensuremath{\PROJ{m}{\SPCY}}}}
\newcommand*{\QnX}{{\ensuremath{\COPROJ{n}{\SPCX}}}}
\newcommand*{\QmY}{{\ensuremath{\COPROJ{m}{\SPCY}}}}
\newcommand*{\FT}{\OP{F}}



% Discretization
\newcommand*{\DISCR}[2]{{\ensuremath{\mathfrak{D}_{#1}(#2)}}}
\newcommand*{\DISCRnX}{\DISCR{n}{X}}
\newcommand*{\DISCRmY}{\DISCR{m}{Y}}
\newcommand*{\DISCRkZ}{\DISCR{k}{Z}}


% Useful math delimiter macros using mathtools
% A macro \CMD supports three usage types:
% 1. \CMD{<arg>}  --  standard size delimiters
% 2. \CMD[<size modifier>]{<arg>}  --  adds <size modifier> to the delimiters, e.g. \big, \Big, \bigg, \Bigg
% 3. \CMD*{<arg>}  --  adds \left and \right to the respective delimiters

% SET
% Syntax: \SET{ <element> \GIVEN <condition> }
\providecommand\GIVEN{}  % just to make sure it exists
% can be useful to refer to this outside \SET
\newcommand{\SETSYMBOL}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}\allowbreak}
\DeclarePairedDelimiterX{\SET}[1]{\lbrace}{\rbrace}{\renewcommand \GIVEN{\SETSYMBOL[\delimsize]} #1 }

% INTERVALS: (C)losed, (O)pen, (R)ight-open or (L)eft-open
\DeclarePairedDelimiterX{\CINTERV}[2]{[}{]}{{#1},{#2}}
\DeclarePairedDelimiterX{\OINTERV}[2]{(}{)}{{#1},{#2}}
\DeclarePairedDelimiterX{\RINTERV}[2]{[}{)}{{#1},{#2}}
\DeclarePairedDelimiterX{\LINTERV}[2]{(}{]}{{#1},{#2}}


% ABS, NORM, INNER etc.
% Empty arguments are replaced with \cdot, i.e., \NORM{} is equivalent to \NORM{\:\cdot\:}
\DeclarePairedDelimiterX{\ABS}[1]{\lvert}{\rvert}{\ifblank{#1}{\:\cdot\:}{#1}}

% Syntax: \NORM{<arg>} or \NORMIN{<subscript>}{<arg>}
\DeclarePairedDelimiterX{\NORM}[1]{\lVert}{\rVert}{\ifblank{#1}{\,\cdot\,}{#1}}
\DeclarePairedDelimiterXPP{\NORMIN}[2]{}{\lVert}{\rVert}{_{#1}}{\ifblank{#2}{\,\cdot\,}{#2}}
% Shortcuts for frequently used spaces
\DeclarePairedDelimiterXPP{\NORMINX}[1]{}{\lVert}{\rVert}{_\SPCX}{\ifblank{#1}{\,\cdot\,}{#1}}
\DeclarePairedDelimiterXPP{\NORMINY}[1]{}{\lVert}{\rVert}{_\SPCY}{\ifblank{#1}{\,\cdot\,}{#1}}
\DeclarePairedDelimiterXPP{\NORMINZ}[1]{}{\lVert}{\rVert}{_\SPCZ}{\ifblank{#1}{\,\cdot\,}{#1}}
\DeclarePairedDelimiterXPP{\NORMINFn}[1]{}{\lVert}{\rVert}{_n}{\ifblank{#1}{\,\cdot\,}{#1}}
\DeclarePairedDelimiterXPP{\NORMINFm}[1]{}{\lVert}{\rVert}{_m}{\ifblank{#1}{\,\cdot\,}{#1}}

% Syntax: \INNER{<arg1>}{<arg2>} or \INNERIN{<subscript>}{<arg1>}{<arg2>}
\DeclarePairedDelimiterX{\INNER}[2]{\langle}{\rangle}{\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\, #2}}
\DeclarePairedDelimiterXPP{\INNERIN}[3]{}{\langle}{\rangle}{_{#1}}{%
\ifblank{#2}{\:\cdot\,}{#2},\ifblank{#3}{\,\cdot\,}{\,#3}%
}
% Shortcuts for frequently used spaces
\DeclarePairedDelimiterXPP{\INNERINX}[2]{}{\langle}{\rangle}{_\SPCX}{%
\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\,#2}%
}
\DeclarePairedDelimiterXPP{\INNERINY}[2]{}{\langle}{\rangle}{_\SPCY}{%
\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\,#2}%
}
\DeclarePairedDelimiterXPP{\INNERINZ}[2]{}{\langle}{\rangle}{_\SPCZ}{%
\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\,#2}%
}
\DeclarePairedDelimiterXPP{\INNERINFn}[2]{}{\langle}{\rangle}{_n}{%
\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\,#2}%
}
\DeclarePairedDelimiterXPP{\INNERINFm}[2]{}{\langle}{\rangle}{_m}{%
\ifblank{#1}{\:\cdot\,}{#1},\ifblank{#2}{\,\cdot\,}{\,#2}%
}


% Sets and properties
\DeclareMathOperator{\RANK}{{rank}}
\DeclareMathOperator{\RANGE}{{ran}}
\DeclareMathOperator{\DOMAIN}{{dom}}
\DeclareMathOperator{\NULL}{{N}}
\DeclareMathOperator{\SPAN}{{span}}
\DeclareMathOperator{\SUPP}{{supp}}
\DeclareMathOperator{\SINC}{{sinc}}
\DeclareMathOperator{\DIM}{{dim}}
\DeclareMathOperator{\DIAG}{{diag}}
\DeclareMathOperator{\TRIDIAG}{{tridiag}}
\DeclareMathOperator{\SHOULDEQ}{{\,\stackrel{!}{=}\,}}
\DeclareMathOperator{\DEFEQ}{{\coloneqq}}
\DeclareMathOperator{\EQDEF}{{\eqqcolon}}


% Misc useful stuff
\newcommand*{\CCONJ}[1]{{\ensuremath{\overline{#1}}}}
\DeclareMathOperator{\ID}{Id}
\newcommand*{\FUNCRESTR}[2]{{\ensuremath{\left. \vphantom{g_{g_g}} {#1} \right|_{#2}}}}
\newcommand*{\TRANSP}[1]{{\ensuremath{#1^{\mathrm{T}}}}}
\newcommand*{\HERM}[1]{{\ensuremath{#1^{\mathrm{H}}}}}
\newcommand*{\I}{\ensuremath{\mathit{i}}}
\newcommand*{\STACK}[2]{{\ensuremath{\genfrac{}{}{0pt}{0}{#1}{#2}}}}
\newcommand*{\STACKSS}[2]{{\ensuremath{\genfrac{}{}{0pt}{1}{#1}{#2}}}}
\newcommand*{\STACKSSS}[2]{{\ensuremath{\genfrac{}{}{0pt}{2}{#1}{#2}}}}
\newcommand*{\D}{{\ensuremath{\mathrm{d}}}}


\newcommand*{\ie}{\textsl{i.e.}\xspace}
\newcommand*{\cf}{\textsl{cf.}\xspace}
\newcommand*{\eg}{\textsl{e.g.}\xspace}
\newcommand*{\etc}{\textsl{e.t.c.}\xspace}
\newcommand*{\wrt}{{w.r.t.}\@\xspace}


\newcommand*{\BDZERO}{\boldsymbol{0}}
\newcommand*{\BDe}{\boldsymbol{e}}
\newcommand*{\BDf}{\boldsymbol{f}}
\newcommand*{\BDg}{\boldsymbol{g}}
\newcommand*{\BDalpha}{\boldsymbol{\alpha}}
\newcommand*{\BDbeta}{\boldsymbol{\beta}}
\newcommand*{\BDnu}{\boldsymbol{\nu}}
\newcommand*{\BDA}{\boldsymbol{A}}
\newcommand*{\BDB}{\boldsymbol{B}}
\newcommand*{\BDD}{\boldsymbol{D}}
\newcommand*{\BDF}{\boldsymbol{F}}
\newcommand*{\BDG}{\boldsymbol{G}}
\newcommand*{\BDI}{\boldsymbol{I}}
\newcommand*{\BDU}{\boldsymbol{U}}
\newcommand*{\BDV}{\boldsymbol{V}}
\newcommand*{\BDSigma}{\boldsymbol{\Sigma}}


\newcommand*{\NOTE}[2][\null]{%
  \marginpar{\renewcommand{\baselinestretch}{1}\vspace{-1em}\hrule\vspace{3pt}%
  \scriptsize\raggedright\textsf{#2\ifx#1\null\else\\\hfill---
  {\em #1}\fi}\vspace{1.5em}}%
}


\crefname{equation}{}{}
\Crefname{equation}{}{}
\crefname{item}{}{}
\Crefname{item}{}{}

\title{The discretization problem and associated software type system}
\author{Ozan \"Oktem \and Holger Kohr}

\begin{document}
\maketitle





\section{Introduction}
\label{sec:intro}
%
In many applications one works with mappings between infinite-dimensional vector spaces.
To numerically deal with such mappings, one is forced to find a finite-dimensional 
counterpart. The process of mapping a vector space to a finite-dimensional one is called
\emph{discretization}. A discretization of a specific space is intimately 
tied to the numerical methodology that one eventually wishes to use. However, many concepts
and results about discretizations can be stated in a general mathematical framework.  

Most complex numerical software packages work with several different discretizations, even
of the same vector space. The general mathematical theory that formalizes the process of
discretization yields consistency checks and recipes for how to switch between two
discretizations. Still, most numerical software packages do not utilize such consistency
checks and, even though changes between two discretizations are explicitly coded, this
code is often scattered throughout or even repeated in different parts of the software package.  

To minimize software bugs, it is therefore desirable to be able to abstract and isolate those parts 
of the code that deal with the discretization. To achieve this, the software must be able to represent 
the abstract process of discretization, and an object oriented framework appears to be most
suitable. We will in this note describe those parts of the abstract mathematical theory that
need to be captured by a numerical software package in able to achieve the above stated goals.
We start by giving the basic mathematical foundations.

In many cases, such as inverse problems arising in applications, one has to deal with 
the following problem: Let $\SPCX$ and $\SPCY$ be infinite-dimensional vector spaces and 
$\OPT \colon \SPCX \to \SPCY$. Consider now the following problem:
%
\begin{equation}
 \label{eq:intro:operator_eq}
 \text{Given $g\in \SPCY$, find $f\in \SPCX$ such that}\quad \OPT(f)=g. 
\end{equation}
%
The operator $\OPT$ can either be given explicitly by a closed form expression, or it can be defined 
implicitly, \eg, as a solution operator to a differential equation. 

In order to numerically work with \cref{eq:intro:operator_eq} in a software package, one must replace the 
infinite-dimensional vector spaces $\SPCX$ and $\SPCY$ with some finite-dimensional 
counterparts $\Fn$ and $\Fm$ with $\FIELD = \RR \text{ or } \CC$, and the map 
$\OPT \colon \SPCX \to \SPCY$ with an appropriate discretized operator 
$\DISCOPT_{m,n}$. This process yields the following system of (linear or nonlinear) equations
with finitely many unknowns:
%
\begin{equation}
 \label{eq:intro:discr_operator_eq}
 \text{Given $\BDbeta \in \Fm$, find $\BDalpha \in \Fn$ such that }\quad \DISCOPT_{n,m} (\BDalpha)=\BDbeta. 
\end{equation}
%
The above process of replacing \cref{eq:intro:operator_eq} with \cref{eq:intro:discr_operator_eq} is referred to 
as \emph{discretization} of \cref{eq:intro:operator_eq}. A general theory of discretizations is outlined in 
\cite[Chapter~34]{ZeIIB85}, see also \cite{Pe93}, but the results are of little use for ill-posed inverse 
problems since the discretized problem \cref{eq:intro:discr_operator_eq} does not fulfill the requirements.
\emph{In this note we only consider a discretization of \cref{eq:intro:operator_eq} as a way of reducing an equation in 
infinite-dimensional setting to an equation \cref{eq:intro:discr_operator_eq} in a finite-dimensional setting.}
Thus, we now formally introduce the notion of discretization in different contexts along with elementary properties.





\section{General definition of discretization}
\label{sec:discr}



\subsection{Discretization of vector spaces}
\label{subsec:discr:space}

We start out by defining the discretization of a (infinite-dimensional) vector space with the help of 
reduction and extension operators.

\begin{definition}
 \label{def:discr:space:space_discr}
 Let $\SPCX$ be a vector space over a field $\FIELD = \RR \text{ or } \CC$, and $n \in \NN$.
 An \emph{$n$-dimensional discretization $\DISCRnX$ of $\SPCX$} is the tuple
 %
 \begin{equation*}
  \DISCRnX \DEFEQ  \bigl( \SPCX, \Fn, \RnX, \EnX \bigr) 
 \end{equation*}
 %
 where $\RnX \colon \SPCX \to \Fn$ and $\EnX \colon \Fn \to \SPCX$. The mappings $\RnX$ and $\EnX$ 
 are called the \emph{restriction} and \emph{extension} operators associated with the discretization. 
 $\DISCRnX$ is a \emph{linear discretization} whenever both these mappings are linear.\\
 %
 There are two additional important mappings derived from $\RnX$ and $\EnX$,
 %
 \begin{align*}
  & \PnX \colon \SPCX \to \SPCX \quad \text{with} \quad \PnX \DEFEQ  \RnX \circ \EnX, \\
  & \QnX \colon \Fn \to \Fn \quad \text{with} \quad \QnX \DEFEQ  \EnX \circ \RnX,
 \end{align*}
 %
 which we refer to as \emph{projection} operators associated with the discretization (although they are not 
necessarily  projections in the strict sense).
\end{definition}


\begin{examp}
 We begin with considering the case where $\SPCX$ is an $n$-dimensional vector space over $\FIELD$. Then $\SPCX$ is 
 isomorphic to $\Fn$, so we may choose $\EnX \DEFEQ \RnX\DEFEQ \OPID$. The resulting discretization 
 $( \Fn, \Fn, \OPID, \OPID )$ is called 
 the \emph{identity discretization}. 
\end{examp}


\begin{examp}
 A common way to discretize a (possibly infinite-dimensional) vector space $\SPCX$ is as follows. Let 
 $\psi_1, \dots, \psi_n \in \SPCX$ be linearly independent space elements and 
 $\lambda_1, \dots, \lambda_n \in \SPCX^*$ be linearly independent functionals on $\SPCX$. Then, restriction and 
 extension operators can be defined as
 %
 \begin{equation*}
  \RnX(f) \DEFEQ  \big( \lambda_1(f), \dots, \lambda_n(f) \big) 
  \quad \text{and} \quad
  \EnX(\BDalpha) \DEFEQ  \sum_{i=1}^n \alpha_i\, \psi_i.
 \end{equation*}
 %
 The corresponding projection operators are
 %
 \begin{equation*}
  \PnX(f) \DEFEQ  \sum_{i=1}^n \lambda_i(f)\, \psi_i
  \quad \text{and} \quad
  \EnX(\BDalpha) \DEFEQ  \bigg( \sum_{j=1}^n \alpha_j\, \lambda_i(\psi_j) \bigg)_{i=1}^n.
 \end{equation*}

\end{examp}


\subsubsection{Discretization of product spaces}
\label{subsubsec:discr:space:prod}

In mathematics it is rather common to construct a new vector space from a collection of vector spaces. If the vector 
spaces in this collection all have discretizations, then one can use these discretizations to define a natural 
discretization on the aforementioned new vector space.

\begin{definition}
 \label{def:discr:space:prod:prod_space_discr}
 Let $\SPCX_i$ for $i=1,\dots,k$ be vector spaces over $\FIELD$ with $n_i$-dimensional discretizations 
 $\DISCR{n_i}{\SPCX_i}$ given as
 %
 \begin{equation*}
  \DISCR{n_i}{\SPCX_i} \DEFEQ  \bigl( \SPCX_i, \FIELD^{n_i}, \REST{n_i}{\SPCX_i}, \EXT{n_i}{\SPCX_i} \bigr). 
 \end{equation*}
 %
 Then the \emph{product discretization of $\SPCX \DEFEQ  \SPCX_1 \times \dots \times \SPCX_k$} is defined as 
 %
 \begin{equation*}
  \DISCR{N}{\SPCX} \DEFEQ \{\SPCX, \FIELD^N, \REST{N}{\SPCX}, \EXT{N}{\SPCX} \}
 \end{equation*}
 %
 with $N \DEFEQ  n_1 + \dots + n_k$, where
 %
 \begin{align*}
  \REST{N}{\SPCX}(f_1,\dots,f_k) &\DEFEQ  \bigl( \REST{n_1}{\SPCX_1}(f_1),\dots,\REST{n_k}{\SPCX_k}(f_k) \bigr)
  \quad\text{for $f_i\in \SPCX_i$, $i=1,\dots,k$} \\
  \EXT{N}{\SPCX}(f_1,\dots,f_k) &\DEFEQ  \bigl( \EXT{n_1}{\SPCX_1}(\BDalpha_1),\dots,\EXT{n_k}{\SPCX_k}(\BDalpha_k) 
  \bigr)
  \quad\text{for $\BDalpha_i\in \FIELD^{n_i}$, $i=1,\dots,k$.}
 \end{align*}
\end{definition}

%
Common special cases of product discretizations are $\SPCX\DEFEQ \FIELD \times \SPCX_2$, which corresponds to the 
case 
$k=2$ and $\SPCX_1=\FIELD$ with the identity discretization.



\subsection{Natural discretization of operators}
\label{subsec:discr:operator}

When given an operator $\OPT$ between vector spaces $\SPCX$ and $\SPCY$, each with a given discretization, 
there is a natural discretized counterpart $\DISCOPT \colon \Fn \to \Fm$ defined as follows:

\begin{definition}
 \label{def:discr:operator:operator_discr}
 Let $\OPT\colon \SPCX \to \SPCY$ be an operator and $\DISCRnX$ and $\DISCRmY$ be 
 discretizations of the vector spaces as in \Cref{def:discr:space:space_discr}. The 
 \emph{natural operator discretization of $\OPT$} is defined as $\DISCOPT \colon \Fn \to \Fm$ given as 
 $\DISCOPT \DEFEQ  \RmY \circ \OPT \circ \EnX$.
\end{definition}


\subsubsection{Natural discretization of spaces of linear operators}
\label{subsubsec:discr:operator:linop_space}

The above notion of a natural operator discretization immediately induces a natural discretization of the space of 
linear operators from $\SPCX$ to $\SPCY$.

\begin{definition}
 \label{def:discr:operator:linop_space:linop_space_discr}
 Let $\SPCX$ and $\SPCY$ be vector spaces with discretizations $\DISCRnX$ and $\DISCRmY$ 
 as in \Cref{def:discr:space:space_discr}. Let further $\SPCL \DEFEQ  \LINOP{\SPCX}{\SPCY}$ be the 
 vector space of linear operators from $\SPCX$ to $\SPCY$. The \emph{natural discretization of $\SPCL$} is 
 given by
 %
 \begin{equation*}
  \DISCR{m\times n}{\SPCL} = \left( \SPCL, \Fmxn, \REST{m\times n}{\SPCL}, \EXT{m\times n}{\SPCL}
  \right)
 \end{equation*}
 %
 with the operators
 %
 \begin{equation*}
  \REST{m\times n}{\SPCL}(\OPT) \DEFEQ  \RmY \circ \OPT \circ \EnX
  \quad\text{and}\quad
  \EXT{m\times n}{\SPCL}(\DISCOPT) \DEFEQ  \EmY \circ \DISCOPT \circ \RnX.
 \end{equation*}
 %
 We have here identified a linear operator from $\Fn$ to $\Fm$ with $\Fmxn$, the vector space 
 of $(m \times n)$ matrices with elements in $\FIELD$.
\end{definition}

\begin{remark}
 From the above considerations it becomes clear that it only makes sense to apply linear discretizations since 
 otherwise, the discretization of a linear operator is not necessary linear. \textbf{Hence, from now on, all 
 discretizations are assumed to be linear.}\\
 %
 Furthermore, a direct application of the same technique to the space of general (nonlinear) operators is not possible 
 since the same operator $\REST{m\times n}{\SPCL}$ would produce nonlinear mappings $\Fn \to \Fm$, which is 
 not compatible to our definition of space discretizations, \cf \Cref{def:discr:space:space_discr}.
\end{remark}


\subsubsection{Natural discretization of operator derivatives}
\label{subsubsec:discr:operator:op_deriv}

For $k \in \NN$, the $k$'th Fr\'{e}chet derivative of a $k$ times continuously differentiable operator 
$\OPT \colon \SPCX \to \SPCY$ is defined as a mapping
%
\begin{equation*}
 \partial^k \OPT \colon \SPCX \to \SPCL^k(\SPCX, \SPCY),
\end{equation*}
%
where $\SPCL^k$ is recursively defined as 
%
\begin{equation*}
 \SPCL^0(\SPCX, \SPCY) \DEFEQ  \SPCY, \quad 
 \SPCL^k(\SPCX, \SPCY) \DEFEQ  \SPCL\big( \SPCX, \SPCL^{k-1}(\SPCX, \SPCY) \big).
\end{equation*}
%
This recursion can be resolved by setting
%
\begin{equation*}
 \bar\partial^k \OPT \colon \SPCX \times \SPCX^k \to \SPCY
 \quad \text{with} \quad
 \bar\partial^k \OPT(f; h_1, \dots, h_k) \DEFEQ  \partial^k\OPT(f)(h_1)\cdots(h_k).
\end{equation*}
%
By definition, $\bar\partial^k\OPT$ is $k$-linear in the last $k$ arguments. We adopt this viewpoint in the following 
and write $\partial^k$ instead of $\bar\partial^k$.\\
%
The natural discretization of a product space as given in \Cref{def:discr:space:prod:prod_space_discr} induces a 
natural discretization of the $k$'th derivative similar to the natural operator discretization in 
\Cref{def:discr:operator:operator_discr}.

\begin{definition}
 \label{def:discr:operator:op_deriv:operator_deriv_discr}
 Let $\SPCX$ and $\SPCY$ be normed vector spaces with discretizations $\DISCRnX$ and $\DISCRmY$, 
 respectively. Let further $\OPT \in \BLINOP{\SPCX}{\SPCY}$ be a $k$ times continuously Fr\'{e}chet 
 differentiable operator for some $k \in  \NN$. The \emph{natural discretization of the $k$'th derivative} 
 $\partial^k \OPT \colon \SPCX \times \SPCX^k \to \SPCY$ is defined as the mapping
 %
 \begin{equation*}
  \partial^k \DISCOPT \colon \Fn \times \FIELD^{k\cdot n} \to \Fm
  \quad \text{with} \quad
  \partial^k \DISCOPT = \RmY \circ \partial^k \OPT \circ (\EnX)^{k+1}.
 \end{equation*}
 %
 The notation $(\EnX)^{k+1}$ stands for the $(k+1)$-tuple $(\EnX, \dots, \EnX)$, i.e., 
 %
 \begin{equation*}
  \partial^k \OPT \circ (\EnX)^{k+1}(\BDalpha; \BDbeta_1, \dots, \BDbeta_k) \DEFEQ 
 \partial^k \OPT\big( \EnX(\BDalpha); \EnX(\BDbeta_1), \dots, \EnX(\BDbeta_k) \big).
 \end{equation*}
\end{definition}


The following lemma shows that under rather weak conditions on the mappings $E_n^{\SPCX}$ and $R_m^{\SPCY}$, the 
natural discretization of the operator derivative as in \Cref{def:discr:operator:op_deriv:operator_deriv_discr} is in 
fact the Fr\'{e}chet derivative of the natural operator discretization.


\begin{lemma}
 \label{lemma:discr:operator:op_deriv:natural_is_deriv}
 Let $\SPCX$ and $\SPCY$ be normed vector spaces with discretizations as before, and let 
 $\OPT \in \BLINOP{\SPCX}{\SPCY}$ be a $k$ times continuously Fr\'{e}chet differentiable 
 operator. If $E_n^{\SPCX}$ and $R_m^{\SPCY}$ are bounded, the natural discretization $\DISCOPT$ of $\OPT$ is 
 $k$ times  continuously Fr\'{e}chet differentiable, and its $k$'th Fr\'{e}chet derivative is the natural 
 discretization of $\partial^k\OPT$.
\end{lemma}
\vspace{1em}


\begin{proof}
 We prove the claim for $k=1$ since the statement for $k=0$ is trivial, and higher order derivatives follow by 
 induction.\\
 %
 For $\BDalpha,\BDbeta \in \Fn$, it is
 %
 \begin{equation*}
  \DISCOPT(\BDalpha + \BDbeta) = \RmY \circ \OPT \circ \EnX (\alpha + \beta).
 \end{equation*}
 %
 From the definition of $\partial \OPT$ it follows that
 %
 \begin{align*}
  \OPT\big(\EnX(\BDalpha + \BDbeta)\big)
  &= \OPT\big(\EnX(\BDalpha)\big) + \partial\OPT\big(\EnX(\BDalpha)\big)\big(\EnX(\BDbeta)\big) +
  o\big(\NORMINX[\big]{\EnX(\BDbeta)}\big) \\
  &= \OPT \circ \EnX(\BDalpha) + \partial\OPT\circ (\EnX)^2\,(\BDalpha; \BDbeta) + o\big(\NORMINFn{\BDbeta} \big)
 \end{align*}
 %
 for $\NORMINFn{\BDbeta} \to 0$ since $\EnX$ is a bounded operator. By composing from left with the bounded operator 
 $\RmY$, one gets
 %
 \begin{align*}
  \DISCOPT(\BDalpha + \BDbeta)
  &= \RmY \circ \OPT \circ \EnX(\BDalpha) + \RmY \circ \partial\OPT\circ (\EnX)^2\,(\BDalpha)(\BDbeta) +
  o\big(\NORMINFn{\BDbeta} \big) 
  \\
  &= \DISCOPT(\alpha) + \RmY \circ \partial\OPT\circ (\EnX)^2\,(\BDalpha)(\BDbeta) + o\big(\NORMINFn{\BDbeta} \big),
 \end{align*}
 %
 hence $\partial\DISCOPT$ is by definition given by the second term.
\end{proof}


\subsubsection{Natural discretization of the adjoint}
\label{subsubsec:discr:operator:op_adj}

If $\SPCX$ and $\SPCY$ are Hilbert spaces over the same field, one can consider the adjoint operator 
$\OPT^* \colon \SPCY \to \SPCX$ and its natural discretization. The following lemma clarifies under which 
conditions this discretization is the adjoint of the operator discretization $\DISCOPT$.


\begin{lemma}
 \label{lemma:discr:operator:op_adj:natural_is_adj}
 Let $\SPCX$ and $\SPCY$ are Hilbert spaces with linear discretizations as in 
 \Cref{def:discr:space:space_discr}, and let $\OPT \colon \SPCX \to \SPCY$ be a bounded linear operator. 
 Then the natural discretization of $\OPT^*$ given by
 %
 \begin{equation*}
  \DISCOPT^* \colon \Fm \to \Fn
  \quad \text{with} \quad
  \DISCOPT^* \DEFEQ  \RnX \circ \OPT^* \circ \EmY
 \end{equation*}
 %
 is the adjoint of the natural discretization $\DISCOPT \DEFEQ  \RmY \circ \OPT \circ \EnX$ of $\OPT$ if the 
operators 
 $\EnX$ and $\RmY$ are bounded and additionally satisfy
 %
 \begin{equation*}
  \EnX = (\RnX)^* \quad \text{and} \quad \EmY = (\RmY)^*.
 \end{equation*}
\end{lemma}
\vspace{1em}


\begin{proof}
 Since $\EnX$ and $\RmY$ are bounded and linear, the same is true for $\DISCOPT$. Its adjoint is given by
 %
 \begin{equation*}
  \DISCOPT^* = (\RmY \circ \OPT \circ \EnX)^* = (\EnX)^* \circ \OPT^* \circ (\RmY)^*,
 \end{equation*}
 %
 which is apparently equal to the natural discretization $\RnX \circ \OPT^* \circ \EmY$ of $\OPT^*$ under the 
 stated conditions.
\end{proof}

\begin{remark}
 This statement can be generalized to densely defined linear operators since a unique adjoint exists also for this 
 class of operators. Another possible generalization is to dual pairings and instead of Hilbert spaces. The same rules 
 as above apply for these operators when chained with bounded linear operators from left or right.
\end{remark}


\subsubsection{Natural discretization of compositions}
\label{subsubsec:discr:operator:op_comp}

Mappings or operators can be chained if their domains and ranges are compatible. We investigate how the natural 
discretization of an operator composition relates to the composition of the single discretized operators.


\begin{lemma}
 \label{lemma:discr:operator:op_comp:natural_is_comp}
 Let $\SPCX, \SPCY$ and $\SPCZ$ be vector spaces with discretizations $\DISCRnX$, 
 $\DISCRmY$ and $\DISCRkZ$, respectively. Let further
 %
 \begin{equation*}
  \OPT \colon \SPCX \to \SPCY \quad \text{and} \quad \OPU \colon \SPCY \to \SPCZ
 \end{equation*}
 %
 be given operators. The natural discretization
 %
 \begin{equation*}
  \DISCOP{S}\colon \Fn \to \Fk 
  \quad \text{with} \quad
  \DISCOP{S} \DEFEQ  \REST{k}{\SPCZ} \circ \OPU \circ \OPT \circ \EnX
 \end{equation*}
 %
 of the operator composition $\OPU \circ \OPT$ is equal to the composition of the discretized operators
 %
 \begin{equation*}
  \DISCOPT \DEFEQ  \RmY \circ \OPT \circ \EnX
  \quad \text{and} \quad
  \DISCOPU = \REST{k}{\SPCZ} \circ \OPU \circ \EmY
 \end{equation*}
 %
 if either the operator $\PmY = \EmY \circ \RmY$ is the identity on the range of $\OPT \circ \EnX$ or if for each 
 $\BDnu \in \Fk$, the preimage $(\REST{k}{\SPCZ} \circ \OPU)^{-1}(\{\BDnu\})$ is invariant under 
 $\PmY$.
\end{lemma}
\vspace{1em}


\begin{proof}
 Obviously, it is
 %
 \begin{equation*}
  \DISCOPU \circ \DISCOPT = \REST{k}{\SPCZ} \circ \OPU \circ \EmY \circ \RmY \circ \OPT \circ \EnX,
 \end{equation*}
 %
 which is equal to $\DISCOP{S}$ as defined above if the factor $\PmY = \EmY \circ \RmY$ can be dropped. This is the 
 case under the given condition as shown in the proof of \Cref{lemma:prop:corresp:natural_op_discr_corresp}.
\end{proof}



\subsection{Correspondence principle}
\label{subsec:discr:corresp}

We proceed by investigating conditions that a discretization should fulfill. Often, we need to perform various 
operations on $\SPCX$, and there are corresponding operations on $\Fn$. It is then important that such 
operations are compatible \wrt the discretization. In the general setting, most of these operations can be stated as 
mappings between appropriately chosen vector spaces. Thus, we begin with defining the notion of compatibility of 
mappings \wrt discretizations. 
%
\begin{definition}
 \label{def:discr:corresp:operator_compat}
 Let $\SPCX$ and $\SPCY$ be vector spaces over $\FIELD$ with discretizations $\DISCRnX$ and 
 $\DISCRmY$, respectively. Now, consider the operators
 %
 \begin{equation*}
  \OPT \colon \SPCX \to \SPCY \quad\text{and}\quad \DISCOPT \colon \Fn \to \Fm.
 \end{equation*}
 \vspace{-2\baselineskip}
 \begin{enumerate}[(a)]
  \item \label{def:discr:corresp:operator_compat:a_exact}
  \emph{$\DISCOPT$ exactly corresponds to $\OPT$ under the discretizations $\DISCRnX$ and  
  $\DISCRmY$} if the following holds for any $n,m \in \NN$:
  %
  \begin{equation*}
   \RmY \circ \OPT = \DISCOPT \circ \RnX  \quad\text{and}\quad  \EmY \circ \DISCOPT = \OPT \circ \EnX.
  \end{equation*}

  \item \label{def:discr:corresp:operator_compat:b_approx}
  \emph{$\DISCOPT$ approximately corresponds to $\OPT$ under the discretizations $\DISCRnX$ and 
  $\DISCRmY$} if the following holds:
  %
  \begin{align*} 
   \lim_{n,m\to \infty} \NORMINFm*{\RmY \circ \OPT - \DISCOPT \circ \RnX} &= 0  \\[0.5em]
   \lim_{n,m\to \infty} \NORMINY*{\EmY \circ \DISCOPT - \OPT \circ \EnX} &= 0.
  \end{align*}
  %
 \end{enumerate}  
 If any of the above holds, then we say that $\DISCOPT$ and $\OPT$ \emph{correspond to each other under the 
 discretizations $\DISCRnX$ and $\DISCRmY$}.
\end{definition}



\subsection{Summary}
\label{subsec:discr:summary}

Let $\FIELD = \RR \text{ or } \CC$ and $m, n, k \in \NN$. We investigated various settings of (natural) 
discretizations as summarized in \Cref{tab:discr:summary:def_summary}.
%
\begin{table}[ht]
 \label{tab:discr:summary:def_summary}
 \renewcommand{\arraystretch}{1.3}
 \begin{tabular}{lll}
  \textbf{Object} & \textbf{(Natural) Discretization} & \textbf{Defined in}                                           \\
  %
  %
  \noalign{\smallskip} \hline\hline \noalign{\smallskip}
  %
  %
  Vector space             & $\DISCRnX = (\SPCX, \Fn, \RnX, \EnX)$                                   & 
  \Cref{def:discr:space:space_discr}                                                                                  \\
  $\SPCX$ over $\FIELD$  & $\RnX \colon \SPCX \to \Fn$ linear                                               &\\
                           & $\EnX \colon \Fn \to \SPCX$ linear                                               &\\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Product space            & $\DISCR{N}{\SPCX} = (\SPCX, \FIELD^N, \REST{N}{\SPCX}, \EXT{N}{\SPCX})$          & 
  \Cref{def:discr:space:prod:prod_space_discr}                                                                        \\
  $\SPCX = \bigotimes_{i=1}^k \SPCX_i$ & $N = \sum_{i=1}^k n_i$                                                  &\\
                           & $\REST{N}{\SPCX} = \big( \REST{n_1}{\SPCX_1}, \dots, \REST{n_k}{\SPCX_k} \big)$  &\\
                           & $\EXT{N}{\SPCX} = \big( \EXT{n_1}{\SPCX_1}, \dots, \EXT{n_k}{\SPCX_k} \big)$     &\\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Operator $\OPT \colon \SPCX \to \SPCY$  & $\DISCOPT \colon \Fn \to \Fm$            
  & \Cref{def:discr:operator:operator_discr}                                                                          \\
                           & $\DISCOPT = \RmY \circ \OPT \circ \EnX$                                             &\\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Vector space of         & $\DISCR{m\times n}{\SPCL} = (\SPCL, \Fmxn, \REST{m\times n}{\SPCL},
  \EXT{m\times n}{\SPCL})$ & \Cref{def:discr:operator:linop_space:linop_space_discr}                                \\
  linear operators        & $\Fmxn \simeq L(\Fn, \Fm)$                                        &\\
  $\SPCL = \LINOP{\SPCX}{\SPCY}$ & $\REST{m\times n}{\SPCL}(\OPT) = \RmY \circ \OPT \circ \EnX$               &\\
                          & $\EXT{m\times n}{\SPCL}(\DISCOPT) = \EmY \circ \DISCOPT \circ \RnX$                &\\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Fr\'{e}chet derivative & $\partial^k\DISCOPT \colon \Fn \times \FIELD^{k\cdot n} \to \Fm$              & 
  \Cref{def:discr:operator:op_deriv:operator_deriv_discr}                                                             \\
  $\partial^k \OPT \colon \SPCX\times \SPCX^k \to \SPCY$ & 
  $\partial^k\DISCOPT = \RmY \circ \partial^k \OPT \circ (\EnX)^{k+1}$                                           &\\
                         & $(\EnX)^{k+1} = (\underbrace{\EnX, \dots, \EnX}_{k+1 \text{ operators }})$                \\
  %
  %
  \noalign{\smallskip} \hline\hline \noalign{\smallskip}
  %
  %
  Correspondence of & $\RmY \circ \OPT = \DISCOPT \circ \RnX$ & \Cref{def:discr:corresp:operator_compat} \\
  $\OPT \colon \SPCX \to \SPCY$ and & $\EmY \circ \DISCOPT = \OPT \circ \EnX$                              &\\
  $\DISCOPT \colon \Fn \to \Fm$  &  &                                                                     \\
  %
  %
  \noalign{\smallskip} \hline
 \end{tabular}
 \caption{Summary of definitions in \Cref{sec:discr}}
 \renewcommand{\arraystretch}{1.0}
\end{table}





\section{Mathematical properties of discretizations}
\label{sec:prop}



\subsection{Correspondence}
\label{subsec:prop:corresp}

In the following Lemma, we investigate under which conditions the natural discretization of an operator leads to 
compatibility in the sense of \Cref{def:discr:corresp:operator_compat}. These conditions can be stated more 
specifically in special cases, see \Cref{sec:specif}.


\begin{lemma}
 \label{lemma:prop:corresp:natural_op_discr_corresp}
 Let $\DISCOPT$ be the natural linear discretization of an operator $\OPT$ based on linear space discretizations as 
 in \Cref{def:discr:space:space_discr}, and let $\PnX = \EnX \circ \RnX$ and $\PmY = \EmY \circ \RmY$ as in 
 \Cref{def:discr:space:space_discr}. Then the following holds:
 
 \begin{enumerate}[(a)]
  \item \label{lemma:prop:corresp:natural_op_discr_corresp:a_general}
  $\DISCOPT$ and $\OPT$ exactly correspond to each other if and only if (1) for each $\BDbeta \in \Fm$, the 
  preimage $(\RmY \circ \OPT)^{-1}(\{\BDbeta\})$ is invariant under $\PnX$ and (2) $\PmY$ is the identity operator on 
  the range of $\OPT \circ \EnX$.

  \item \label{lemma:prop:corresp:natural_op_discr_corresp:b_hilbert_linear}
  If $\SPCX$ is a Hilbert space and $\OPT$ and $\RmY$ are linear and bounded, the condition on $\PnX$ in 
  \eqref{lemma:prop:corresp:natural_op_discr_corresp:a_general} can be rephrased as the following: 
  (1a) $\PnX$ is equal to the identity operator on $\NULL(\RmY \circ \OPT)^\perp$ and (1b) 
  $\NULL(\RmY \circ \OPT)$ is invariant under $\PnX$.
  
  \todo{Maybe one should say something about approximate correspondence if possible.}
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item Right-composing the discretized operator $\DISCOPT = \RmY \circ \OPT \circ \EnX$ with $\RnX$ results in
  %
  \begin{equation*}
   \DISCOPT \circ \RnX = \RmY \circ \OPT \circ \PnX,
  \end{equation*}
  %
  and by left-composing $\DISCOPT$ with $\EmY$, we get
  %
  \begin{equation*}
   \EmY \circ \DISCOPT = \PmY \circ \OPT \circ \EnX.
  \end{equation*}
  %
  Let now $\BDbeta \in \Fm$ be arbitrary and $A \DEFEQ  (\RmY \circ \OPT)^{-1}(\{\BDbeta\})$ be its preimage.
  To show the ``if'' part, we observe that for each $f \in A$, it is $\PnX(f) \in A$ since $A$ is invariant under 
  $\PnX$. Hence, $\RmY \circ \OPT \big( \PnX(f) \big) = \BDbeta$. This shows 
  $\RmY \circ \OPT \circ \PnX = \RmY \circ \OPT$, i.e. the first condition 
  in \Cref{def:discr:corresp:operator_compat}~\eqref{def:discr:corresp:operator_compat:a_exact} is fulfilled.\\
  %
  Obviously, if $\PmY$ is the identity on the range of $\OPT \circ \EnX$, the right hand side of the second identity 
  is $\PmY \circ \OPT \circ \EnX = \OPT \circ \EnX$. This implies the second equation in 
  \Cref{def:discr:corresp:operator_compat}~\eqref{def:discr:corresp:operator_compat:a_exact} and concludes this part of 
  the proof.\\
  %
  For the ``only if'' part, we assume that there is $f \in A$ with $\PnX(f) \not\in A$. By definition, this means 
  $\RmY \circ \OPT \big( \PnX(f) \big) \neq \BDbeta$, which violates the condition
  $\BDbeta = \RmY \circ \OPT (f) = \RmY \circ \OPT \circ \PnX (f)$. Hence, $A$ must be invariant under $\PnX$.\\
  %
  Apparently, $\PmY \circ \OPT \circ \EnX = \OPT \circ \EnX$ means that for each $g = \OPT \circ \EnX(\BDalpha)$, 
  it holds $\PmY(g) = g$, i.e. $\PmY$ is the identity on the range of $\OPT \circ \EnX$.

  \item To prove \eqref{lemma:prop:corresp:natural_op_discr_corresp:b_hilbert_linear}, we first observe that 
  $\NULL(\RmY \circ \OPT) = (\RmY \circ \OPT)^{-1}(\{\BDZERO\})$. Further, since $\SPCX$ is a Hilbert space 
  and $\RmY \circ \OPT$ linear and bounded, each $f \in \SPCX$ can be uniquely decomposed into 
  $f = f_0 + \tilde f$ with  $f_0 \in \NULL(\RmY \circ \OPT)$ and 
  $\tilde f \in \NULL(\RmY \circ \OPT)^\perp$. Hence, for each $\BDbeta \in \Fm$,
  %
  \begin{equation*}
   (\RmY \circ \OPT)^{-1}({\BDbeta}) = \tilde f + \NULL(\RmY \circ \OPT)
  \end{equation*}
  %
  for a unique $\tilde f \in \NULL(\RmY \circ \OPT)^\perp$. Thus, the conditions on $\PnX$ in 
  \eqref{lemma:prop:corresp:natural_op_discr_corresp:b_hilbert_linear} are equivalent to those in   
  \eqref{lemma:prop:corresp:natural_op_discr_corresp:a_general}.
  
%  \item 
 \end{enumerate}
\end{proof}



\subsection{Compatibility of linear combinations}
\label{subsec:prop:lincomb}

Let $\SPCX$ be a vector space over $\FIELD$ with its usual discretization. The linear combination in vector spaces 
can be formally defined as an operator, and as such it implies a natural discretization. In the following, we 
investigate how it relates to the usual linear combination in $\Fn$ and under which conditions they correspond to 
each other.


\begin{lemma}
 \label{lemma:prop:lincomb:natural_corresp}
 Let $\SPCX$ be a vector space over $\FIELD$ with linear discretization $\DISCRnX$.
 \begin{enumerate}[(a)]
  \item The linear combination in $\Fn$ is the natural discretization of the linear combination in $\SPCX$ if 
  and only if the projection $\QnX = \RnX \circ \EnX$ is the identity.
  
  \item The linear combinations in $\SPCX$ and $\Fn$ exactly correspond to each other.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item The linear combination in $\SPCX$ can be written as an operator 
  %
  \begin{equation*}
   \OPT \colon \FIELD \times \FIELD \times \SPCX \times \SPCX \to \SPCX
   \quad \text{with} \quad
   \OPT(\mu, \lambda, f, g) \DEFEQ  \lambda \cdot f + \mu \cdot g
  \end{equation*}
  %
  with natural discretization $\DISCOPT = \RnX \circ \OPT \circ (\OPID, \OPID, \EnX, \EnX)$.
  Hence, for $\lambda, \mu \in \FIELD$ and $\BDalpha, \BDbeta \in \Fn$, it is
  %
  \begin{align*}
   \DISCOPT(\lambda, \mu, \BDalpha, \BDbeta) 
   &= \RnX \circ \OPT \big( \lambda, \mu, \EnX(\BDalpha), \EnX(\BDbeta) \big)\\
   &= \RnX \big( \lambda \cdot \EnX(\BDalpha) + \mu \cdot \EnX(\BDbeta) \big) \\ 
   &= \RnX \circ \EnX(\lambda \cdot \BDalpha + \mu \cdot \BDbeta).
  \end{align*}
  %
  This expression is equal to $\lambda \cdot \BDalpha + \mu \cdot \BDbeta$ for all $\lambda, \mu \in \FIELD$ and all 
  $\BDalpha, \BDbeta \in \Fn$ if and only if $\RnX \circ \EnX = \OPID$.

  \item The conditions for exact correspondence according to \Cref{def:discr:corresp:operator_compat} can be 
  rephrased as
  %
  \begin{align*}
   \RnX(\lambda \cdot f + \mu \cdot g) &= \lambda \cdot \RnX(f) + \mu \cdot \RnX(g), \\
   \EnX(\lambda \cdot \BDalpha + \mu \cdot \BDbeta) &= \lambda \cdot \EnX(\BDalpha) + \mu \cdot \EnX(\BDbeta),
  \end{align*}
  %
  and are fulfilled due to the linearity of $\RnX$ and $\EnX$.
 \end{enumerate}
\end{proof}

\begin{remark}
 \label{remark:prop:lincomb:natural_linop_space}
 In the vector space $\SPCL \DEFEQ  \BLINOP{\SPCX}{\SPCY}$ with given discretizations in $\SPCX$ and $\SPCY$, the 
 natural restriction and extension operators of the discretization $\DISCR{m\times n}{\SPCL}$ are given by
 %
 \begin{equation*}
  \REST{m\times n}{\SPCL}(\OPT) = \RmY \circ \OPT \circ \EnX
  \quad\text{and}\quad
  \EXT{m\times n}{\SPCL}(\DISCOPT) = \EmY \circ \DISCOPT \circ \RnX,
 \end{equation*}
 %
 see \Cref{def:discr:operator:linop_space:linop_space_discr}. Hence, the condition that the natural discretization of 
 the linear combination in $\SPCL$ is the linear combination in $\Fmxn$ reads as
 %
 \begin{align*}
  \DISCOPT 
  &= \REST{m\times n}{\SPCL}\big( \EXT{m\times n}{\SPCL}(\DISCOPT) \big)
  = \RmY \circ \EXT{m\times n}{\SPCL}(\DISCOPT) \circ \EnX
  = \RmY \circ \EmY \circ \DISCOPT \circ \RnX \circ \EnX \\
  &= \QmY \circ \DISCOPT \circ \QnX.
 \end{align*}
 %
 Thus, if $\QnX = \OPID$ and $\QmY = \OPID$, the operator space discretization $\DISCR{m\times n}{\SPCL}$ 
 automatically fulfills the condition $\COPROJ{m\times n}{\SPCL} = \OPID$ needed for the natural discretization of 
 the linear combination.
\end{remark}



\subsection{Compatibility of norms}
\label{subsec:prop:norm}

We now consider the setting when $\SPCX$ is a normed vector space, including the space of bounded linear operators.


\begin{lemma}
 \label{lemma:prop:norm:natural_corresp}
 Let $\SPCX$ be a vector space over $\FIELD$ with norm $\NORMINX{}$ and linear discretization 
 $\DISCRnX$. Let further $\NORMINFn{}$ be a norm in $\Fn$.
 %
 \begin{enumerate}[(a)]
  \item \label{lemma:prop:norm:natural_corresp:a_natural}
  $\NORMINFn{}$ is the natural discretization of $\NORMINX{}$ if and only if
  %
  \begin{equation*}
   \EnX \colon (\Fn, \NORMINFn{}) \to (\SPCX, \NORMINX{})
  \end{equation*}
  %
  is an isometry.
  
  \item \label{lemma:prop:norm:natural_corresp:b_corresp}
  $\NORMINFn{}$ corresponds to $\NORMINX{}$ if and only if
  %
  \begin{equation*}
   \RnX \colon (\SPCX, \NORMINX{}) \to (\Fn, \NORMINFn{})
   \quad \text{and} \quad
   \EnX \colon (\Fn, \NORMINFn{}) \to (\SPCX, \NORMINX{})
  \end{equation*}
  %
  are isometries.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}
 We write the norm as an operator
 %
 \begin{equation*}
  \OPT \colon \SPCX \to \RR \quad \text{with} \quad \OPT(f) \DEFEQ  \NORMINX{f}.
 \end{equation*}
 %
 Its natural discretization is given by
 %
 \begin{equation*}
  \DISCOPT \colon \Fn \to \RR \quad \text{with} \quad \DISCOPT = \OPID \circ \OPT \circ \EnX,
 \end{equation*}
 %
 \ie, $\DISCOPT(\BDalpha) = \NORMINX*{\EnX(\BDalpha)}$. This proves the claim in 
 \eqref{lemma:prop:norm:natural_corresp:a_natural}.\\
 %
 The conditions for correspondence read as
 %
 \begin{equation*}
  \NORMINX{} = \NORMINFn{} \circ \RnX
  \quad \text{and} \quad
  \NORMINFn{} = \NORMINX{} \circ \EnX
 \end{equation*}
 %
 and are equivalent to the isometry conditions in \eqref{lemma:prop:norm:natural_corresp:b_corresp}.
\end{proof}

\begin{remark}
 The proof additionally shows that the natural norm discretization fulfills
 $\DISCOPT(\BDalpha) \leq \NORM{\EnX}\, \NORMINFn{\BDalpha}$, i.e. the discretized norm can be bounded from above 
 with the given norm in $\Fn$.
\end{remark}


\paragraph{Operator norms}

In a similar way, we can analyze the relation between norms of continuous and discretized linear operators. 
The norms of operators $\OPT \in \SPCL \DEFEQ  \BLINOP{\SPCX}{\SPCY}$ and 
$\DISCOPT \in \SPCL(\Fn, \Fm) \simeq \Fmxn$ are defined as
%
\begin{equation*}
 \NORMIN{\SPCL}{\OPT} \DEFEQ  \sup_{\NORMINX{f} \leq 1} \NORMINY*{\OPT(f)}
 \quad \text{and} \quad
 \NORMIN{m\times n}{\DISCOPT} \DEFEQ  \sup_{\NORMINFn{\BDalpha} \leq 1} \NORMINFn*{\DISCOPT(\BDalpha)}.
\end{equation*}
%
The following Lemma shows how operator and matrix norms relate to each other under discretization.


\begin{lemma}
 \label{lemma:prop:norm:op_norm_est}
 Let $\SPCX$ and $\SPCY$ be normed vector spaces with linear discretizations $\DISCRnX$ and 
 $\DISCRmY$, respectively. Let further $\REST{m\times n}{\SPCL}(\OPT)$ and 
 $\EXT{m\times n}{\SPCL}(\DISCOPT)$ be the natural restriction and extension operators in 
 $\DISCR{m\times n}{\SPCL}$ as given in \Cref{def:discr:operator:linop_space:linop_space_discr}.
 %
 \begin{enumerate}[(a)]
  \item \label{lemma:prop:norm:op_norm_est:a_rest}
  If the operator norms of $\RmY$ and $\EnX$ are bounded by 1, then
  %
  \begin{equation*}
   \NORMIN*{\BLINOP{\SPCL}{\Fmxn}}{\REST{m\times n}{\SPCL}} \leq 1.
  \end{equation*}
  %
  Furthermore, if $\RmY$ and $\EnX$ are isometries and $\RmY$ is surjective, $\EXT{m\times n}{\SPCL}$ is an 
  isometry, \ie, $\NORMIN{m\times n}{}$ is the natural discretization of $\NORMIN{\SPCL}{}$.
  
  \item \label{lemma:prop:norm:op_norm_est:b_ext}
  If the operator norms of $\RnX$ and $\EmY$ are bounded by 1, then
  %
  \begin{equation*}
   \NORMIN*{\BLINOP{\Fmxn}{\SPCL}}{E_{m\times n}^{\SPCL}} \leq 1.
  \end{equation*}
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item For $\OPT \in \SPCL$ and $\DISCOPT = \REST{m\times n}{\SPCL}(\OPT)$ we have
  %
  \begin{equation*}
   \NORMINFm*{\DISCOPT(\BDalpha)} = \NORMINFm*{\RmY \left( \OPT\big( \EnX(\BDalpha) \big) \right)}
   \leq \NORMINY*{\OPT\big( \EnX(\BDalpha) \big)}
  \end{equation*}
  %
  since $\NORM{\RmY} \leq 1$. Furthermore, $\EnX$ maps the unit ball in $\Fn$ to a subset of the unit ball in
  $\SPCX$ since $\NORM{\EnX} \leq 1$. Hence,
  %
  \begin{equation*}
   \sup_{\NORMINFn{\BDalpha} \leq 1} \NORMINY*{\OPT\big( \EnX(\BDalpha) \big)}
   = \sup_{\substack{f=\EnX(\BDalpha)\\ \NORMINFn{\BDalpha} \leq 1}} \NORMINY*{\OPT(f)}
   \leq \sup_{\NORMINX{f} \leq 1} \NORMINY*{\OPT(f)},
  \end{equation*}
  %
  which proves that $\NORM*{\REST{m\times n}{\SPCL}(\OPT)} \leq \NORM{\OPT}$.

  \item Analogously, for $\DISCOPT \in \Fmxn$ and $\OPT = \EXT{m\times n}{\SPCL}(\DISCOPT)$ it is
  %
  \begin{equation*}
   \NORMINY*{\OPT(f)} = \NORMINY*{\EmY \left( \DISCOPT\big( \RnX(f) \big) \right)}
   \leq \NORMINFm{\DISCOPT\big( \RnX(f) \big)}
  \end{equation*}
  %
  since $\NORM{\EmY} \leq 1$. In addition, $\RnX$ maps the unit ball in $\SPCX$ to a subset of the unit 
  ball in $\Fn$ since $\NORM{\RnX} \leq 1$. Hence,
  %
  \begin{equation*}
   \sup_{\NORMINX{f} \leq 1} \NORMINFm{\DISCOPT\big( \RnX(f) \big)}
   = \sup_{\STACKSS{\BDalpha=\RnX(f)}{\NORMINX{f} \leq 1}} \NORMINFm{\DISCOPT(\BDalpha)}
   \leq \sup_{\NORMINFn{\BDalpha} \leq 1} \NORMINFm{\DISCOPT(\BDalpha)},
  \end{equation*}
  %
  \ie, $\NORM*{E_{m\times n}^{\SPCL}(\DISCOPT)} \leq \NORM{\DISCOPT}$.\\[1em]
  %
  If $\EmY$ is an isometry, the first inequality becomes an equality, and if $\RnX$ is a surjective isometry, it maps
  the unit ball in $\SPCX$ \emph{onto} the unit ball in $\Fn$. Thus, also the second inequality becomes an 
  equality, showing that $\NORM*{\EXT{m\times n}{\SPCL}(\DISCOPT)} = \NORM{\DISCOPT}$ for all 
  $\DISCOPT \in \Fmxn$ in this case. According to 
  \Cref{lemma:prop:norm:natural_corresp}~\eqref{lemma:prop:norm:natural_corresp:a_natural}, this means that the natural 
  operator norm discretization is the matrix norm in $\Fmxn$.
 \end{enumerate}
\end{proof}


\begin{remark}
 \label{remark:prop:norm:op_norm_corresp}
 An analogous isometry property for $\REST{m\times n}{\SPCL}$ can only hold if $\DIM(\SPCX) \leq n$ 
 since it requires the extension map $\EnX \colon \Fn \to \SPCX$ to be surjective. Hence, exact correspondence 
 of a matrix norm to an operator norm is only possible for certain finite-dimensional spaces $\SPCX$.\\
 %
 In any case, the inequalities ensure that one can get an estimate for the operator norm of $\OPT$ (restricted to the 
 range of $\EnX$) in terms of the discretized (matrix) norm of $\DISCOPT$, which can be very useful in numerical 
 computations.
\end{remark}



\subsection{Compatibility of inner products}
\label{subsec:prop:inner}

Now we consider inner product spaces and analyze their behavior under discretization.


\begin{lemma}
 \label{lemma:prop:inner:natural_corresp}
 Let $\big( \SPCX, \INNERINX{}{} \big)$ be an inner product space with discretization $\DISCRnX$, and 
 let $\INNERIN{n}{}{}$ be the inner product in $\Fn$.
 %
 \begin{enumerate}[(a)]
  \item \label{lemma:prop:inner:natural_corresp:a_natural}
  $\INNERINFn{}{}$ is the natural discretization of the inner product $\INNERINX{}{}$ if and 
  only if $\EnX$ is unitary.
  
  \item \label{lemma:prop:inner:natural_corresp:b_corresp}
  $\INNERINFn{}{}$ exactly corresponds to $\INNERINX{}{}$ if and only if both $\RnX$ and 
  $\EnX$ are unitary.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item We define the inner product as an operator
  %
  \begin{equation*}
   \OPT \colon \SPCX \times \SPCX \to \FIELD
   \quad \text{with} \quad
   \OPT(f, g) \DEFEQ  \INNERINX{f}{g}.
  \end{equation*}
  %
  The natural discretization of this operator is given by $\DISCOPT = \OPID \circ \OPT \circ (\EnX, \EnX)$, \ie,
  %
  \begin{align*}
   \DISCOPT(\BDalpha, \BDbeta) 
   &= \OPT\big( \EnX(\BDalpha), \EnX(\BDbeta) \big) 
   = \INNERINX[\big]{\EnX(\BDalpha)}{\EnX(\BDbeta)} \\
   &= \INNERINFn[\big]{(\EnX)^* \circ \EnX(\BDalpha)}{\BDbeta}.
  \end{align*}
  %
  Apparently, this expression is equal to $\INNERINFn{\BDalpha}{\BDbeta}$ if and only if $\EnX$ is unitary.

  \item The conditions for exact correspondence can be written as
  %
  \begin{equation*}
   \INNERINX{f}{g} = \INNERINFn[\big]{\RnX(f)}{\RnX(g)}
   \quad \text{and} \quad
   \INNERINFn{\BDalpha}{\BDbeta} = \INNERINX[\big]{\EnX(\BDalpha)}{\EnX(\BDbeta)},
  \end{equation*}
  %
  which is equivalent to the conditions in the claim.
 \end{enumerate}
\end{proof}



\subsection{Summary}
\label{subsec:prop:summary}

We summarize the properties of linear discretizations along with the corresponding conditions. Recall the definitions 
of 
the (projection) operators
%
\begin{equation*}
 \PnX = \EnX \circ \RnX \colon \SPCX \to \SPCX
 \quad \text{and} \quad
 \QnX = \RnX \circ \EnX \colon \Fn \to \Fn,
\end{equation*}
%
see \Cref{def:discr:space:space_discr}.%
%
\renewcommand{\arraystretch}{1.1}%
\begin{longtable}{>{\raggedright}p{0.30\linewidth}<{\raggedright} %
                  >{\raggedright}p{0.45\linewidth}<{\raggedright} %
                  p{0.15\linewidth}}
  \multicolumn{3}{c}{\textbf{Natural discretization = known operation}} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  \textbf{Object} & \textbf{Conditions} & \textbf{Shown in} \endfirsthead 
  \textbf{Object} & \textbf{Conditions} & \textbf{Shown in} \endhead 
  %
  %
  \noalign{\smallskip} \hline\hline \noalign{\smallskip}
  %
  %
  Fr\'{e}chet derivative &
  $\EnX, \RmY$ bounded &
  \Cref{lemma:discr:operator:op_deriv:natural_is_deriv} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Adjoint &
  $\EnX = \big( \RnX \big)^*$ and $\EmY = \big( \RmY \big)^*$ &
  \Cref{lemma:discr:operator:op_adj:natural_is_adj} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Operator composition of $\OPT \colon \SPCX \to \SPCY$ and $\OPU \colon \SPCY \to \SPCZ$ &
  Either $\PmY$ identity on $\RANGE(\OPT \circ \EnX)$ or single-element preimages of 
  $\REST{k}{\SPCZ} \circ \OPU$ invariant under $\PmY$ &
  \Cref{lemma:discr:operator:op_comp:natural_is_comp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Linear combination &
  $\QnX$ identity &
  \Cref{lemma:prop:lincomb:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Linear combination in $\BLINOP{\SPCX}{\SPCY}$ under natural discretization &
  $\QnX$ and $\QmY$ identity operators &
  \Cref{remark:prop:lincomb:natural_linop_space} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Norm &
  $\EnX$ isometry &
  \Cref{lemma:prop:norm:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Operator norm under natural discretization &
  $\RmY, \EnX$ isometries and $\RmY$ surjective &
  \Cref{lemma:prop:norm:op_norm_est} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Inner product &
  $\EnX$ unitary &
  \Cref{lemma:prop:inner:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}%
 \caption{Summary of the results on natural discretization as given in \Cref{sec:prop}}%
 \label{tab:prop:summary:natural_summary}%
\end{longtable}%
\renewcommand{\arraystretch}{1.0}%
%
\noindent
\Cref{tab:prop:summary:natural_summary} shows the results regarding the equality of natural discretizations and known 
operations in the discretized spaces, and \Cref{tab:prop:summary:exact_corresp_summary} is an overview of the results 
on exact correspondence.
\newpage
%
\renewcommand{\arraystretch}{1.1}
\begin{longtable}{>{\raggedright}p{0.30\linewidth}<{\raggedright} %
                  >{\raggedright}p{0.45\linewidth}<{\raggedright} %
                  p{0.15\linewidth}}
  \multicolumn{3}{c}{\textbf{Exact correspondence}} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  \textbf{Object} & \textbf{Conditions} & \textbf{Shown in} \endfirsthead
  \textbf{Object} & \textbf{Conditions} & \textbf{Shown in} \endhead
  %
  %
  \noalign{\smallskip} \hline\hline \noalign{\smallskip} 
  %
  %
  $\DISCOPT = \RmY \circ \OPT \circ \EnX$ (natural operator discretization) &
  (1) Single-element preimages of $\RmY \circ \OPT$ are invariant under $\PnX$ and & 
  \Cref{lemma:prop:corresp:natural_op_discr_corresp} \\
  %
  &
  (2) $\PmY$ is the identity on $\RANGE(\OPT \circ \EnX)$ &
  \\
  \noalign{\smallskip}
  Special case: $\SPCY$ Hilbert space and $\OPT$ linear and &
  (1a) $\PnX$ is identity on $\NULL(\RmY \circ \OPT)^\perp$ and &
  \\
  bounded &
  (1b) $\NULL(\RmY \circ \OPT)$ invariant under $\PnX$ and (2) as above &
  \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Linear combination &
  None beyond linearity &
  \Cref{lemma:prop:lincomb:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Norm &
  $\RnX$ and $\EnX$ isometries &
  \Cref{lemma:prop:norm:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Operator norm under natural discretization &
  $\RnX, \EnX, \RmY, \EmY$ isometries and $\EnX, \RmY$ surjective &
  \Cref{lemma:prop:norm:op_norm_est} \\
  &
  (implies $\DIM(\SPCX) \leq n$) &
  \Cref{remark:prop:norm:op_norm_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  Inner product &
  $\RnX, \EnX$ unitary &
  \Cref{lemma:prop:inner:natural_corresp} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
 \caption{Summary of the conditions for exact correspondence in different situations as analyzed in \Cref{sec:prop}}
 \label{tab:prop:summary:exact_corresp_summary}
\end{longtable}
\renewcommand{\arraystretch}{1.0}





\section{Specific discretizations}
\label{sec:specif}

We will now consider various specific discretizations and investigate their properties in the light of the 
results in \Cref{sec:prop}.



\subsection{Functionals and dictionaries}
\label{subsec:specif:funct}

Let $\SPCX$ be a vector space over $\FIELD$ and $\Lambda = \{\lambda_1, \dots, \lambda_n\}$ a set of linear mappings
$\lambda_i \colon \SPCX \to \FIELD$. With those we define the restriction mapping
%
\begin{equation*}
 \RnX \colon \SPCX \to \Fn \quad \text{as} \quad \RnX(f) \DEFEQ  \big( \lambda_i(f) \big)_{i=1}^n.
\end{equation*}
%
Let further $\Phi=\SET{\phi_1, \dots, \phi_n} \subset \SPCX$ be a set of elements (a \emph{dictionary}) 
in 
$\SPCX$. We 
define the extension operator
%
\begin{equation*}
 \EnX \colon \Fn \to \SPCX \quad \text{as} \quad \EnX(\BDalpha) \DEFEQ  \sum_{i=1}^n \alpha_i\, \phi_i.
\end{equation*}
%
The corresponding projection operators are then given by
%
\begin{equation*}
 \PnX(f) \DEFEQ  \sum_{i=1}^n \lambda_i(f)\, \phi_i
 \quad \text{and} \quad
 \left[ \QnX \right]_{i,j} \DEFEQ  \lambda_i(\phi_j),\quad i,j=1,\dots,n.
\end{equation*}
%
For these specific operators, we can rephrase some of the properties arising as conditions in \Cref{sec:discr,sec:prop} 
in terms of $\Lambda$ and $\Phi$. We start with the general vector space case and proceed with normed spaces and 
Hilbert spaces.


\begin{lemma}~
 \label{lemma:specif:funct:op_prop_vecspace}
 \begin{enumerate}[(a)]
  \item \label{lemma:specif:funct:op_prop_vecspace:Q_identity}
  $\QnX = \BDI$ if and only if $\lambda_i(\phi_j) = \delta_{i,j},\ i,j=1,\dots,n$.
  
  \item \label{lemma:specif:funct:op_prop_vecspace:R_surjective}
  $\RnX$ is surjective if and only if $\Lambda$ is linearly independent.
  
  \item \label{lemma:specif:funct:op_prop_vecspace:E_surjective}
  $\EnX$ is surjective if and only if $\SPCX = \SPAN(\Phi)$.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}
 Obvious.
\end{proof}


\begin{lemma}
 \label{lemma:specif:funct:op_prop_normedspace}
 Let $\SPCX$ and $\Fn$ be normed spaces and let the norm $\NORMINFn{}$ fulfill the norm equivalence
 %
 \begin{equation*}
  c_1 \NORMINFn{} \leq \NORMIN{\mathrm{M}}{} \leq C_1 \NORMINFn{}
 \end{equation*}
 %
 with constants $0 < c_1 \leq C_1$, where $\NORMIN{\mathrm{M}}{}$ is the ``Manhattan''- or 1-norm.

 \begin{enumerate}[(a)]
  \item \label{lemma:specif:funct:op_prop_normedspace:R_bounded}
  $\NORMINFn*{\RnX(f)} \leq c_1^{-1} \sum_{i=1}^n \ABS{\lambda_i(f)}$, \ie, $\RnX$ is bounded if and only if all 
  mappings $\lambda_i$ are bounded (\emph{functionals}).
  %
  \item \label{lemma:specif:funct:op_prop_normedspace:E_bounded}
  $\NORMINX*{\EnX(\BDalpha)} \leq C_1\, \max_i \NORMINX{\phi_i}\, \NORMINFn{\BDalpha}$, hence $\EnX$ is bounded.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item It is
  %
  \begin{align*}
   \NORMINFn{\RnX(f)} 
   &= \NORMINFn{\big( \lambda_1(f), \dots, \lambda_n(f) \big)} \\
   &\leq c_1^{-1} \sum_{i=1}^n \ABS{\lambda_i(f)} \leq n\,c_1^{-1}\, \max_i \ABS{\lambda_i(f)}
  \end{align*}
  %
  according to the norm equivalence. This proves the claim.
  
  \item For the operator $\EnX$, we use the triangle inequality and the norm equivalence to get
  %
  \begin{align*}
   \NORMINX{\EnX(\BDalpha)} 
   &= \NORMINX[\bigg]{\sum_{i=1}^n \alpha_i\, \phi_i} \leq \sum_{i=1}^n \ABS{\alpha_i}\, \NORMINX{\phi_i} 
\\
   &\leq \max_i \NORMINX{\phi_i}\, \NORMIN{\mathrm{M}}{\BDalpha} \leq C_1\, \max_i \NORMINX{\phi_i}\, 
   \NORMINFn{\BDalpha}.
  \end{align*}
 \end{enumerate}
\end{proof}

\begin{lemma}
 \label{lemma:specif:funct:op_prop_hilbert}
 Let $\SPCX$ and $\Fn$ be Hilbert spaces. Let further $\BDA \in \Fnxn$ be the Hermitian positive 
 definite matrix defining the inner product in $\Fn$, \ie,
 %
 \begin{equation*}
  \INNERINFn{\BDalpha}{\BDbeta} \EQDEF \HERM{\BDbeta} \BDA \BDalpha
 \end{equation*}
 %
 with $\HERM{\BDalpha} \DEFEQ  \TRANSP{\CCONJ{\BDalpha}}$. The norms in $\SPCX$ and $\Fn$ be defined via 
 the respective inner products. Let further $\Theta \subset \SPCX$ be the Riesz representants of the functionals 
 $\lambda_i$ in the sense that
 \begin{equation*}
  \lambda_i = \INNERINX{}{\theta_i}
  \quad \text{for} \quad 
  i=1,\dots,n.
 \end{equation*}
 %
 \begin{enumerate}[(a)]
  \item \label{lemma:specif:funct:op_prop_hilbert:Q_identity}
  $\QnX$ is the identity if and only if the sets $\Theta$ and $\Phi$ are bi-orthogonal, \ie, 
  $\INNERINX{\phi_i}{\theta_j} = \delta_{i,j}$.
 
  \item \label{lemma:specif:funct:op_prop_hilbert:R_adjoint_repr}
  The adjoint operators $(\RnX)^*$ and $(\EnX)^*$ have the representations
  %
  \begin{equation*}
   (\RnX)^*(\BDalpha) = \sum_{i=1}^n (\BDA \BDalpha)_i\, \theta_i
   \quad \text{and} \quad
   (\EnX)^*(f) = \BDA^{-1} \BDbeta(f)
  \end{equation*}
  %
  with $\BDbeta(f) \DEFEQ \big( \INNERINX{f}{\phi_i} \big)_{i=1,\dots,n}$.
  
  \item \label{lemma:specif:funct:op_prop_hilbert:R_E_adjoint_relation}
  It is $(\RnX)^* = \EnX$ if and only if $\TRANSP{\BDA}$ is the change-of-basis matrix from $\Theta$ to $\Phi$, \ie,
  %
  \begin{equation*}
   \phi_j = \sum_{i=1}^n A_{i,j}\, \theta_i, \quad j=1,\dots,n.
  \end{equation*}
  %
  This implies in particular that the linear spans of $\Theta$ and $\Phi$ are identical.
 
  \item  \label{lemma:specif:funct:op_prop_hilbert:E_isometry}
  $\EnX$ is an isometry if and only if $\Phi$ is linearly independent and $\TRANSP{\BDA}$ is the Gramian matrix 
  $\BDG_\Phi$ defined by $(G_\Phi)_{i,j} \DEFEQ  \INNERINX{\phi_i}{\phi_j}$.
  
  \item \label{lemma:specif:funct:op_prop_hilbert:R_isometry}
  $\RnX$ is an isometry if and only if $\DIM(\SPCX) = n$, $\Theta$ is linearly independent and $\BDA$ is the 
  inverse of the Gramian matrix $\BDG_\Theta$.
 \end{enumerate}
\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item This is an immediate consequence of \Cref{lemma:specif:funct:op_prop_vecspace}.
 
  \item To find a representation for the $(\RnX)^*$, we calculate
  %
  \begin{align*}
   \INNERINFn[\big]{\RnX(f)}{\BDalpha} 
   &= \HERM{\BDalpha} \BDA \RnX(f)
   = \sum_{i,j=1}^n \CCONJ{\alpha_i}\, A_{i,j}\, \INNERINX{f}{\theta_j} 
   = \INNERINX[\bigg]{f}{\sum_{i,j=1}^n A_{j,i}\, \alpha_i\, \theta_j} \\
   &= \INNERINX[\bigg]{f}{\sum_{j=1}^n (\BDA \BDalpha)_j\, \theta_j},
  \end{align*}
  %
  from which the first claim follows. Likewise, it is
  %
  \begin{equation*}
   \INNERINX[\big]{\EnX(\BDalpha)}{f}
   = \sum_{i=1}^n \alpha_i\, \INNERINX{\phi_i}{f}
   = \HERM{\BDbeta(f)} \BDalpha
   = \INNERINFn[\big]{\BDalpha}{\BDA^{-1} \BDbeta(f)},
  \end{equation*}
  %
  and the adjoint of $\EnX$ can be read off this identity.

  \item For each $f \in \SPCX$, we require $\RnX(f) = (\EnX)^*(f)$, \ie,
  %
  \begin{equation*}
   \BDbeta(f) = \BDA \RnX(f) 
   \quad \Leftrightarrow \quad
   \INNERINX{f}{\phi_i} = \sum_{j=1}^n A_{i,j}\, \INNERINX{f}{\theta_j}
   = \INNERINX[\bigg]{f}{\sum_{j=1}^n A_{j,i} \theta_j},
  \end{equation*}
  %
  which implies the claimed relation.
  
  \item It is
  %
  \begin{equation*}
   \NORMINX*{\EnX(\BDalpha)}^2 = \NORMINX[\Big]{\sum_{i=1}^n \alpha_i\, \phi_i}^2 = 
   \sum_{i,j=1}^n \alpha_i\, \CCONJ{\alpha_j}\, \INNERINX{\phi_i}{\phi_j} 
   = \HERM{\BDalpha} \TRANSP{\BDG_\Phi} \BDalpha.
  \end{equation*}
  %
  The Gramian matrix transpose $\TRANSP{\BDG_\Phi}$ is nonsingular and thus defines an inner product if and only if 
  $\Phi$ is linearly independent. Since bilinear forms are uniquely determined by their diagonals, this proves 
  \eqref{lemma:specif:funct:op_prop_hilbert:E_isometry}.
  
  \item As a linear operator with finite-dimensional range, $\RnX$ is compact and thus has a singular value 
  decomposition
  %
  \begin{equation*}
   \RnX(f) = \sum_{k=1}^n \sigma_k\, \INNERINX{f}{v_k}\, u_k
  \end{equation*}
  %
  with singular system $(v_k, u_k; \sigma_k)_{k=1, \dots, \DIM(\SPCX)}$, where $\sigma_k = 0$ for $k > n$. Hence, it 
  is
  %
  \begin{equation*}
   \NORMINFn[\big]{\RnX(f)}^2 = \sum_{k=1}^n \sigma_k^2\, \ABS[\big]{\INNERINX{f}{v_k}}^2 
   = \sum_{k=1}^{\DIM(\SPCX)} \ABS[\big]{\INNERINX{f}{v_k}}^2 = \NORMINX{f}^2
  \end{equation*}
  %
  for all $f\in\SPCX$ if and only if $\DIM(\SPCX) = n$ and $\sigma_k = 1$ for all $k$. By applying the SVD
  representation of $\RnX$ to $\theta_j$, we have
  %
  \begin{equation*}
   \big[ \RnX(\theta_i) \big]_j = \INNERINX{\theta_i}{\theta_j} = \sum_{k=1}^n 
   \INNERINX{\theta_i}{v_k}\, u_{k,j},
  \end{equation*}
  %
  which reads as $\BDG_\Theta = \BDG_{\Theta,V} \BDU$ with 
  $(G_{\Theta,V})_{i,j} \DEFEQ  \INNERINX{\theta_i}{v_j}$ and the matrix $\BDU$ consisting of the singular   
  vectors $u_k$ as rows. Likewise, applying $\RnX$ to $v_i$ yields
  %
  \begin{equation*}
   \big[ \RnX(v_i) \big]_j = \INNERINX{v_i}{\theta_j} = u_{i,j},
  \end{equation*}
  %
  \ie, $\BDU = \BDG_{V,\Theta}$. On the other hand, the unit norm 
  property of the vectors $u_k$ can be written in matrix form as $\BDU \BDA \HERM{\BDU} = \BDI$. Combining these 
properties   results in
  %
  \begin{equation*}
   \BDG_{\Theta,V} = \BDG_{\Theta,V} \BDU \BDA \HERM{\BDU} = \BDG_\Theta \BDA \HERM{\BDU}
   = \BDG_\Theta \BDA \HERM{\BDG_{V,\Theta}} = \BDG_\Theta \BDA \BDG_{\Theta, V},
  \end{equation*}
  %
  which shows that $\BDA = \BDG_\Theta^{-1}$ since $\BDG_{\Theta,V}$ is non-singular.
  \todo{Check if this is correct! Actually one would expect $\TRANSP{\BDA}$.}
 \end{enumerate}
\end{proof}


\begin{corollary}
 \label{coroll:specif:funct:op_prop_hilbert_R_E_adjoint_relation}
 If the conditions of \Cref{lemma:specif:funct:op_prop_hilbert} hold and $\BDG_\Phi$ is a real matrix, $\EnX$ is equal 
 to $(\RnX)^*$ and an isometry -- and thereby also $\RnX$ -- if and only if $\TRANSP{\BDA} = \BDG_\Phi$ with 
 bi-orthogonal dictionaries  $\Phi$ and $\Theta$ which span the same space.
\end{corollary}
\vspace{1em}


\begin{proof}
 For the ``only if'' part, we apply \Cref{lemma:specif:funct:op_prop_hilbert}
 \eqref{lemma:specif:funct:op_prop_hilbert:R_E_adjoint_relation}--\eqref{lemma:specif:funct:op_prop_hilbert:R_isometry},
 to see that $\BDA = \TRANSP{\BDA} = \BDG_\Phi$, \ie,
 %
 \begin{equation*}
  \phi_j = \sum_{i=1}^n \INNERINX{\phi_j}{\phi_i}\, \theta_i.
 \end{equation*}
 %
 On the other hand, $\BDG_\Phi \BDG_\Theta = \BDI$, hence by applying $\INNERINX{}{\theta_k}$ to the identity 
 for $\phi_j$ we get
 %
 \begin{equation*}
  \INNERINX{\phi_j}{\theta_k} 
  = \sum_{i=1}^n \INNERINX{\phi_j}{\phi_i}\, \INNERINX{\theta_i}{\theta_k} = \delta_{j,k},
 \end{equation*}
 %
 which shows that $\Phi$ and $\Theta$ are bi-orthogonal.\\
 %
 Conversely, for the ``if'' part, we assume that $\Theta$ and $\Phi$ are bi-orthogonal and span the same space. Then, 
 we can write
 %
 \begin{equation*}
  \phi_i = \sum_{j=1}^n \alpha_{i,j}\, \theta_j
 \end{equation*}
 %
 with coefficients $\alpha_{i,j} \in \FIELD$. Applying the functional $\INNERINX{}{\theta_k}$ yields
 %
 \begin{equation*}
  \delta_{i,k} = \INNERINX{\phi_i}{\theta_k} = \sum_{j=1}^n \alpha_{i,j}\, 
\INNERINX{\theta_j}{\theta_k},
 \end{equation*}
 %
 which shows that the $\BDG_\Theta^{-1} = \BDG_\Phi$ is the change-of-basis matrix from $\Theta$ to $\Phi$. Thus, the
 proof is complete.
\end{proof}


Now we investigate the conditions for the compatibility of operator discretizations. Let $\SPCX, \SPCY$ be Hilbert 
spaces with discretizations $\DISCRnX$ and $\DISCRmY$, respectively. The inner products in 
$\Fn$ and $\Fm$ be represented by Hermitian positive definite matrices $\BDA \in \Fnxn$ and $\BDB 
\in \Fmxm$, respectively. 
Let further the operators $\RnX$ and $\EnX$ be defined as above, and let
%
\begin{equation*}
 \RmY(g) \DEFEQ  \big( \INNERINY{\xi_j}{g} \big)_{j=1}^m
 \quad \text{and} \quad
 \EmY(\BDbeta) \DEFEQ  \sum_{j=1}^m \CCONJ{\beta_j}\, \psi_j
\end{equation*}
%
with linearly independent systems $\Xi$ and $\Psi$.

\begin{lemma}
 \label{lemma:specif:funct:op_prop_hilbert_mapping}
 Let $0 \neq \OPT\colon \SPCX \to \SPCY$ be a bounded linear operator. 
 
 \begin{enumerate}[(a)]
  \item \label{lemma:specif:funct:op_prop_hilbert_mapping:PmY}
  Let $\SPCY_n \DEFEQ  \RANGE(\OPT \circ \EnX)$ and $m_0 \DEFEQ  \DIM(\SPCY_n)$. $\PmY$ is the identity on 
  $\SPCY_n$ if and only if (after possibly reordering $\Xi$ and $\Psi$,) it holds
  %
  \begin{enumerate}[({a}1)]
   \item \label{lemma:specif:funct:op_prop_hilbert_mapping:PmY:1_range}
   $\SPCY_n = \SPAN(\Xi_{m_0}) = \SPAN(\Psi_{m_0})$ and
   \item \label{lemma:specif:funct:op_prop_hilbert_mapping:PmY:2_biorth}
   $\Xi_{m_0}$ and $\Psi_{m_0}$ are bi-orthogonal
  \end{enumerate}
  %
  where $\Xi_{m_0} \DEFEQ  \{ \xi_j\, |\, j\leq m_0 \}$ and $\Psi_{m_0}$ analogously. This implies the block 
  structures
  %
  \renewcommand{\arraystretch}{1.1}
  \begin{equation*}
   \BDG_{\Xi, \Psi} =
   %
   \left(
   \begin{array}{c|c}
    \BDI_{m_0} & \BDZERO \\[2pt]
    \hline
    \BDZERO & \boldsymbol{\ast}
   \end{array}
   \right),
   %
   \quad
   %
   \BDG_\Xi =
   %
   \left(
   \begin{array}{c|c}
    \BDG_{\Xi_{m_0}} & \BDZERO \\[2pt]
    \hline
    \BDZERO & \boldsymbol{\ast}
   \end{array}
   \right),
   %
   \quad
   %
   \BDG_\Psi =
   %
   \left(
   \begin{array}{c|c}
    \BDG_{\Psi_{m_0}} & \BDZERO \\[2pt]
    \hline
    \BDZERO & \boldsymbol{\ast}
   \end{array}
   \right)
  \end{equation*}
  \renewcommand{\arraystretch}{1.0}
  %
  for the Gramian matrices, where additionally $\BDG_{\Xi_{m_0}} = \BDG_{\Psi_{m_0}}^{-1}$. 

  \item \label{lemma:specif:funct:op_prop_hilbert_mapping:PnX}
  Let $\SPCX_m \DEFEQ  \NULL(\RmY \circ \OPT)^\perp$ and $n_0 \DEFEQ  \DIM(\SPCX_m)$. $\PnX$ is the identity on   
  $\SPCX_m$ if and only if (after possibly reordering $\Theta$ and $\Phi$,)
  \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:1_range}--%
  \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:2_biorth}
  hold for $(\SPCX_m, n_0, \Theta, \Phi)$ instead of $(\SPCY_n, m_0, \Xi, \Psi)$.
 \end{enumerate}

\end{lemma}
\vspace{1em}


\begin{proof}~
 \begin{enumerate}[(a)]
  \item Apparently, it is $\SPCY_n = \RANGE(\OPT \circ \EnX) = \SPAN\big( \OPT(\Phi) \big)$, and $\PmY$ being the 
  identity on $\SPCY_n$ means that
  %
  \begin{equation*}
   \OPP \DEFEQ \FUNCRESTR{\PmY}{\SPCY_n} \colon \SPCY_n \to \SPCY_n
  \end{equation*}
  %
  is the identity operator. To prove the ``if'' part, we observe that for $k\leq m_0$, it is
  %
  \begin{equation*}
   \OPP(\psi_k) = \sum_{j=1}^m \INNERINY{\psi_k}{\xi_j}\, \psi_j = \psi_k
  \end{equation*}
  %
  due to the conditions in 
  \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:1_range}--%
  \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:2_biorth}.
  Hence, $\OPP$ is the identity operator since $\SPAN(\Psi_{m_0}) = \SPCY_n$. \\
  %
  For the ``only if'' part, we write the identity $\OPP = \OPID$ as
  %
  \begin{equation}
   \label{lemma:specif:funct:op_prop_hilbert_mapping:PmY:proof_ident}
   \tag{{$\ast$}}
   \OPT(\phi_i) 
   = \sum_{j=1}^m \INNERINY[\big]{\OPT(\phi_i)}{\xi_j}\, \psi_j, \quad i=1,\dots,n,
  \end{equation}
  %
  and infer that
  %
  \begin{equation*}
   \SPAN\SET{ \xi_j \GIVEN j\leq m_0 } = \SPAN\SET{ \psi_j \GIVEN j\leq m_0 } = \SPCY_n.
  \end{equation*}
  %
  This implies that $\SET{ \xi_j \GIVEN j > m_0 }$ and $\SET{ \psi_j \GIVEN j > m_0 }$ are perpendicular 
to the sets 
  above, \ie,
  %
  \begin{equation*}
   \INNERINY{\xi_j}{\xi_k} = \INNERINY{\psi_j}{\psi_k} = 
\INNERINY{\xi_j}{\psi_k} = 0
  \end{equation*}
  %
  for $k \leq m_0 < j$ or $j \leq m_0 < k$. On the other hand, by applying $\INNERINY{}{\xi_k}$ to 
  \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:proof_ident}, it follows for $k \leq m_0$ and $i=1,\dots,n$ 
  that
  %
  \begin{equation*}
   \INNERINY{\OPT(\phi_i)}{\xi_k}
   = \sum_{j=1}^m \INNERINY[\big]{\OPT(\phi_i)}{\xi_j}\, \INNERINY{\psi_j}{\xi_k}
   = \INNERINY[\bigg]{\OPT(\phi_i)}{\underbrace{\sum_{j=1}^{m_0} \INNERINY{\xi_k}{\psi_j}\, 
\xi_j}_{\in \SPCY_n}},
  \end{equation*}
  %
  and thus $\xi_k = \sum_{j=1}^{m_0} \, \xi_j$. The linear independence of $\Xi$ 
  immediately yields $\INNERINY{\xi_k}{\psi_j} = \delta_{k,j}$ for $k,j \leq m_0$. If we now apply
  $\INNERINY{}{\psi_k}$ to \eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY:proof_ident}, it follows 
analogously 
  that
  %
  \begin{equation*}
   \psi_k = \sum_{j=0}^{m_0} \INNERINY{\psi_k}{\psi_j}\, \xi_j,
  \end{equation*}
  %
  which concludes the proof.
  
  \item By writing $\SPCX_m = \SPAN\big( \OPT^*(\Xi) \big)$, we can use the same arguments as above to prove the claim.
 \end{enumerate}
\end{proof}


\begin{remark}
 The proof shows that the invariance of $\NULL(\RmY \circ \OPT)$ under $\PnX$ follows from the other conditions.
\end{remark}

We conclude this part with a table to summarize the conditions on the extension and restriction operators, expressed in 
terms of the element collections or functionals.
%
\renewcommand{\arraystretch}{1.1}%
\begin{longtable}{>{\raggedright}p{0.28\linewidth}<{\raggedright} %
                  >{\raggedright}p{0.44\linewidth}<{\raggedright} %
                  p{0.17\linewidth}}
  \textbf{Operator condition} & \textbf{Specific condition} & \textbf{Shown in} \endhead
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip} 
  %
  %
  $\QnX$ identity & 
  $\lambda_i(\phi_j) = \delta_{i,j}$ & 
  \Cref{lemma:specif:funct:op_prop_vecspace}~\eqref{lemma:specif:funct:op_prop_hilbert:Q_identity} \\[0.5em]
  %
  (Hilbert space) &
  $\Theta$, $\Phi$ bi-orthogonal &
  \Cref{lemma:specif:funct:op_prop_hilbert}~\eqref{lemma:specif:funct:op_prop_hilbert:Q_identity}\\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\RnX$ surjective &
  $\Lambda$ linearly independent &
  \Cref{lemma:specif:funct:op_prop_vecspace}~\eqref{lemma:specif:funct:op_prop_vecspace:R_surjective} \\[0.5em]
  %
  (Hilbert space) &
  $\Theta$ linearly independent &
  \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\EnX$ surjective &
  $\SPCX = \SPAN(\Phi)$ &
  \Cref{lemma:specif:funct:op_prop_vecspace}~\eqref{lemma:specif:funct:op_prop_vecspace:E_surjective} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\EnX$ bounded &
  None beyond $\Phi \subset \SPCX$ &
  \Cref{lemma:specif:funct:op_prop_normedspace}~\eqref{lemma:specif:funct:op_prop_normedspace:E_bounded} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\RnX$ bounded &
  $\lambda_i$ bounded (functionals) &
  \Cref{lemma:specif:funct:op_prop_normedspace}~\eqref{lemma:specif:funct:op_prop_normedspace:R_bounded} \\[0.5em]
  %
  (Hilbert Space) &
  None beyond $\Theta \subset \SPCX$ &
  \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $(\RnX)^* = \EnX$ &
  $\TRANSP{\BDA}$ change-of-basis matrix from $\Theta$ to $\Phi$, equivalently: &
  \Cref{lemma:specif:funct:op_prop_hilbert}~\eqref{lemma:specif:funct:op_prop_hilbert:R_E_adjoint_relation} \\[0.5em]
  %
  &
  $\Theta$, $\Phi$ bi-orthogonal with identical spans and $\TRANSP{\BDA} = \BDG_\Phi$ &
  \Cref{coroll:specif:funct:op_prop_hilbert_R_E_adjoint_relation} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\EnX$ isometry &
  $\Phi$ linearly independent and $\TRANSP{\BDA} = \BDG_\Phi$  &
  \Cref{lemma:specif:funct:op_prop_hilbert}~\eqref{lemma:specif:funct:op_prop_hilbert:E_isometry} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\RnX$ isometry &
  $\DIM(\SPCX) = n$,  $\Theta$ linearly independent and $\BDA = \BDG_\Theta^{-1}$  &
  \Cref{lemma:specif:funct:op_prop_hilbert}~\eqref{lemma:specif:funct:op_prop_hilbert:R_isometry} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\PmY$ identity on $\SPCY_n$ ($\SPCY_n = \RANGE(\OPT \circ \EnX)$) &
  (1) $\SPCY_n = \SPAN(\Xi_{m_0}) = \SPAN(\Psi_{m_0})$
  (2) $\Xi_{m_0}$ and $\Psi_{m_0}$ bi-orthogonal
  $m_0 = \RANK(\OPT) = \DIM(\SPCY_n)$ &
  \Cref{lemma:specif:funct:op_prop_hilbert_mapping}~\eqref{lemma:specif:funct:op_prop_hilbert_mapping:PmY} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}
  %
  %
  $\PnX$ identity on $\SPCX_m$ ($\SPCX_m = \NULL(\RmY \circ \OPT)^\perp$) &
  (1) $\SPCX_m = \SPAN(\Theta_{n_0}) = \SPAN(\Phi_{n_0})$
  (2) $\Theta_{n_0}$ and $\Phi_{n_0}$ bi-orthogonal
  $n_0 = \DIM(\SPCX_m)$  &
  \Cref{lemma:specif:funct:op_prop_hilbert_mapping}~\eqref{lemma:specif:funct:op_prop_hilbert_mapping:PnX} \\
  %
  %
  \noalign{\smallskip} \hline \noalign{\smallskip}%
 \caption{Summary of the results operator properties in \Cref{subsec:specif:funct}}%
 \label{tab:prop:summary:operator_summary}%
\end{longtable}%
\renewcommand{\arraystretch}{1.0}%





\subsection{Interpolation dictionaries}
\label{subsec:specif:interp}

We now consider the special cases where the dictionary $\Phi$ of the extension operator $\EnX$ corresponds to 
interpolation of a certain order. We derive corresponding bi-orthogonal dictionaries $\Theta$ and give approximation 
formulas for the restriction operator $\RnX$. Orthogonality is established with respect to the $L^2$ scalar product
%
\begin{equation*}
 \INNERIN{L^2}{f}{g} \DEFEQ \int_\RR f(x)\, \CCONJ{g(x)}\, \D x,
\end{equation*}
%
however, the results which make sense in Banach spaces can as be generalized to $L^p$ spaces with $p \neq 2$, where 
$\INNERIN{L^2}{f}{}$ is a functional for certain $f$. The cases covered here, nearest-neighbor and linear 
interpolation, 
can be written as tensor products of one-dimensional interpolation in higher dimensions. Therefore, we cover only the 
1D 
case. \\
%
Let $x_1 < x_2 < \dots < x_n$ be a set of nodes in $\RR$. We define the help nodes $x_0$ 
and $x_{n+1}$ by symmetric continuation, \ie,
%
\begin{equation*}
 x_0 \DEFEQ x_1 - (x_2 - x_1) = 2 x_1 - x_2
 \quad \text{and} \quad
 x_{n+1} \DEFEQ  2 x_n - x_{n-1}.
\end{equation*}
%
For notational reasons, we further define the forward and central distances
%
\begin{equation*}
 h_i \DEFEQ x_{i+1} - x_i
 \quad\text{and}\quad
 \bar h_i \DEFEQ \frac{x_{i+1} - x_{i-1}}{2}
\end{equation*}
%
for $i=0,\dots,n$.

\paragraph{Regular grid}

We also give formulas for the special case of a regular grid with spacing $h>0$. For a more convenient notation, we 
center the grid around a value $x^*\in\RR$ by defining
%
\begin{equation*}
 x_i \DEFEQ x^* + ih,\ i = -\frac{n-1}{2}, \dots, \frac{n-1}{2}.
\end{equation*}
%
Note that for even $n$, the indices are half-integers and $x^*$ is not a node. The forward and central distances are 
obviously constant and equal to $h$ in this case. A further very common specialization is to center the grid around the 
origin, \ie, $x^*=0$.



\subsubsection{Nearest-neighbor interpolation}
\label{subsubsec:specif:interp:nn}

This type of interpolation is defined by a piecewise constant interpolation basis:
%
\begin{equation*}
 \phi_i(x) \DEFEQ 
 \begin{cases}
  1 & \text{if } x - x_i \in \RINTERV[\big]{- \tfrac{h_{i-1}}{2}}{\frac{h_i}{2}}, \\
  0 & \text{else}.
 \end{cases}
\end{equation*}
%
It is clear that $\INNERIN{L^2}{\phi_i}{\phi_j} = 0$ if $i \neq j$ since the supports do not overlap. For 
the diagonal terms, we calculate
%
\begin{equation*}
 \int_\RR \ABS*{\phi_i(x)}^2\, \D x 
 = \int_{x_i - \frac{h_{i-1}}{2}}^{x_i + \frac{h_i}{2}} 1\, \D x
 = \frac{h_{i-1} + h_i}{2} = \frac{x_{i+1} - x_{i-1}}{2}
 \EQDEF \bar h_i
\end{equation*}
%
Hence, $\BDG_\Phi = \DIAG\big( \bar h_i \big)_{i=1,\dots,n}$, and the dictionary $\Theta$ with
%
\begin{equation*}
 \theta_i \DEFEQ \big( \bar h_i \big)^{-1}\, \phi_i
\end{equation*}
%
is the unique dictionary bi-orthogonal to $\Phi$ with the same linear span. The functional 
$\INNERIN{L^2}{}{\theta_i}$ is approximated as
%
\begin{align*}
 \INNERIN{L^2}{f}{\theta_i}
 &= \big( \bar h_i \big)^{-1} \int_{x_i - \frac{h_{i-1}}{2}}^{x_i + 
 \frac{h_i}{2}} f(x)\, \D x \\
 &\approx  \frac{2}{x_{i+1} - x_{i-1}} f\big( x_i \big) \frac{h_{i-1} + h_i}{2} 
 \\
 &= f\big( x_i \big)
\end{align*}
%
by the rectangular (midpoint) integration rule. Thus, the collocation operator at the nodes $x_i$, applied to 
$\bar f$, is an approximation to the restriction operator $\RnX$.

\paragraph{Regular grid}

For $x_i = x^* + i h$, the functions $\phi_i$ are
%
\begin{equation*}
 \phi_i(x) = \phi\big( h^{-1}(x-x_i) \big)
 \quad \text{with} \quad
 \phi(x) \DEFEQ
 \begin{cases}
  1 & \text{if } x \in \CINTERV*{-\tfrac{1}{2}}{\tfrac{1}{2}}, \\
  0 & \text{else},
 \end{cases}
\end{equation*}
%
and the Gramian simplifies to $\BDG_\Phi = h \BDI$. The bi-orthogonal dictionary is simply $\Theta = h^{-1}\Phi$.



\subsubsection{Linear interpolation}
\label{subsubsec:specif:interp:linear}

This continuous interpolation type is defined by the piecewise linear functions 
%
\begin{equation*}
 \phi_i(x) \DEFEQ
 \begin{dcases}
  \frac{x - x_{i-1}}{x_i - x_{i-1}} & \text{if } x \in \CINTERV{x_{i-1}}{x_i}, \\
  \frac{x_{i+1} - x}{x_{i+1} - x_i} & \text{if } x \in \CINTERV{x_i}{x_{i+1}}, \\
  0 & \text{else}.
 \end{dcases}
\end{equation*}
%
To calculate the mutual inner products of the dictionary elements, we observe that 
$\INNERIN{L^2}{\phi_i}{\phi_j} = 0$ if $\ABS{i-j} > 1$. For $j=i+1$, the overlap of the supports is the 
interval ${[x_i, x_{i+1}]}$, and thus
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\phi_{i+1}}
 = \int_{x_i}^{x_{i+1}} \frac{x_{i+1} - x}{h_i} \cdot \frac{x - x_i}{h_i}\, \D x
 = \frac{h_i}{6}.
\end{equation*}
%
For $j=i$, we calculate
%
\begin{align*}
 \INNERIN{L^2}{\phi_i}{\phi_i}
 &= \int_{x_{i-1}}^{x_i} \left( \frac{x - x_{i-1}}{h_{i-1}} \right)^2\, \D x +
 \int_{x_i}^{x_{i+1}} \left( \frac{x_{i+1} - x}{h_i} \right)^2\, \D x \\
 &= \frac{h_{i-1}}{3} + \frac{h_i}{3} 
 = \frac{x_{i+1} - x_{i-1}}{3}
 = \frac{2}{3}\, \bar h_i.
\end{align*}
%
Hence, $\BDG_\Phi$ is a symmetric real tri-diagonal matrix with
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\phi_i} = \frac{2}{3}\, \bar h_i
 \quad \text{and} \quad
 \INNERIN{L^2}{\phi_i}{\phi_{i+1}} = \frac{h_i}{6}.
\end{equation*}
%
As far as the operator $\RnX$ is concerned, we write
%
\begin{align*}
 \INNERIN{L^2}{f}{\theta_i}
 &= \int_\RR f(x)\, \theta_i(x)\, \D x \\
 & \approx \frac{1}{2}\left(
 h_1 \theta_i(x_1) f(x_1) + h_n \theta_i(x_n) f(x_n)  
 \right) + \phantom{x} \\
 &\hspace{10pt} \sum_{j=2}^{n-1} \bar h_j \theta_i(x_j) f(x_j).
\end{align*}
%
The function values $\theta_i(x_j)$ for a bi-orthogonal dictionary $\Theta$ can be calculated with the 
relation
%
\begin{equation*}
 \theta_i(x_j) 
 = \sum_{k=1}^n \INNERIN{L^2}{\theta_k}{\theta_j}\, \phi_k(x_j)
 = \INNERIN{L^2}{\theta_i}{\theta_j}
\end{equation*}
%
since $\phi_k(x_j) = \delta_{k,j}$ by construction. Hence, it is the matrix $\BDG_\Theta = 
\BDG_\Phi^{-1}$ 
that contains the coefficients $g_{i,j} = \INNERIN{L^2}{\theta_i}{\theta_j}$ in the approximation formula
%
\begin{align*}
 \INNERIN{L^2}{f}{\theta_i}
 & \approx \frac{1}{2}\left(
 h_1 g_{i,1} f(x_1) + h_{n-1} g_{i,n} f(x_n)  
 \right) + \phantom{x} \\
 &\hspace{10pt} \sum_{j=2}^{n-1} \bar h_j g_{i,j} f(x_j).
\end{align*}

\begin{remark}
 Numerical tests indicate that the derived formula is rather sensitive with respect to node distribution. It seems to 
 work stably for close to uniformly distributed nodes but fails for large deviations in node spacing. Thus, the 
 approximation formula is rather a theoretical result explaining the relation between the operators $\RnX$ and $\EnX$.
\end{remark}

\paragraph{Regular grid}

It is
%
\begin{equation*}
 \phi_i(x) = \phi\big( h^{-1}(x-x_i) \big)
 \quad \text{with} \quad
 \phi(x) \DEFEQ
 \begin{dcases}
  1 + x & \text{if } x \in \CINTERV{-1}{0}, \\
  1-x & \text{if } x \in \CINTERV{0}{1}, \\
  0 & \text{else},
 \end{dcases}
\end{equation*}
%
and the Gramian matrix is given by $\BDG_\Phi = h/6\cdot \TRIDIAG(1,4,1)$.
%



\subsubsection{Cubic spline interpolation}
\label{subsubsec:specif:interp:cubic}

We use piecewise third order polynomials which are continuous with value 1 at the middle glue point and vanishing first 
derivative at all glue points. These functions can be shown to be given as
%
\begin{equation*}
 \phi_i(x) \DEFEQ
 \begin{dcases}
  -2\left( \frac{x - x_{i-1}}{x_i - x_{i-1}} \right)^3 + 
  3 \left( \frac{x - x_{i-1}}{x_i - x_{i-1}} \right)^2 & \text{ if }
  x \in \CINTERV{x_{i-1}}{x_i}, \\
  -2\left( \frac{x_{i+1} - x}{x_{i+1} - x_i} \right)^3 + 
  3 \left( \frac{x_{i+1} - x}{x_{i+1} - x_i} \right)^2 & \text{ if } 
  x \in \CINTERV{x_i}{x_{i+1}}, \\
  0 & \text{else}.
 \end{dcases}
\end{equation*}
%
As for linear interpolation, one can show that the sum of two neighboring functions at the overlap interval is always 
equal to one. For the Gramian matrix, we get
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\phi_i} = \frac{26}{35}\, \bar h_i, 
 \quad
 \INNERIN{L^2}{\phi_i}{\phi_{i+1}} = \frac{9}{70}\, h_i,
\end{equation*}
%
and the inner products $\INNERIN{L^2}{\phi_i}{\phi_j}$ with $\ABS{i-j} > 1$ are zero.

\paragraph{Regular grid}

Here, the functions $\phi_i$ are given by $\phi_i(x) = \phi\big( h^{-1}(x-x_i) \big)$ with
%
\begin{equation*}
 \phi(x) \DEFEQ
 \begin{dcases}
  -2(1+x)^3 + 3(1+x)^2 & \text{if } x \in \CINTERV{-1}{0}, \\
  -2(1-x)^3 + 3(1-x)^2 & \text{if } x \in \CINTERV{0}{1}, \\
  0 & \text{else}.
 \end{dcases}
\end{equation*}
%
The Gramian is the tridiagonal matrix $\BDG_\Phi = h/70\cdot\TRIDIAG(9, 52, 9)$.


\subsubsection{Sinc dictionary}
\label{subsubsec:specif:interp:sinc}

Let $\SPCX$ be the space of $a$-bandlimited functions with $a > 0$, \ie, 
%
\begin{equation*}
 \SPCX \DEFEQ L^2_a(\RR) \DEFEQ \SET[\big]{f \in L^2(\RR) \GIVEN \SUPP(\FT(f)) \subset \CINTERV{-a}{a}}.
\end{equation*}
%
$\SPCX$ is a reproducing kernel Hilbert space with kernel
%
\begin{equation*}
 K(x,y) \DEFEQ \frac{a}{\pi}\, \SINC\big( a(x-y) \big),
\end{equation*}
%
\ie, it is $f(x) = \INNERIN{L^2}{f}{K(x, \cdot)}$ for each $x\in \RR$. Hence, for a collection of sampling points $x_1, 
\dots, x_n$, we can define
%
\begin{equation*}
 \theta_j \DEFEQ K(x_j, \cdot),
\end{equation*}
%
and the Gramian matrix entries are immediately given by 
%
\begin{equation*}
 \INNERIN{L^2}{\theta_j}{\theta_k} = \theta_j(x_k) 
 = \frac{a}{\pi}\, \SINC\big( a(x_j - x_k) \big).
\end{equation*}
%
The bi-orthogonal dictionary $\Phi$ can be constructed with the relation
%
\begin{equation*}
 \phi_j = \sum_{k=1}^n \INNERIN{L^2}{\phi_k}{\phi_j}\, \theta_k,
\end{equation*}
%
where the inner products are the entries of the transpose of $\BDG_\Phi = \BDG_\Theta^{-1}$ and can hence be calculated 
by matrix inversion. This shows that the usage of the sinc dictionary is inconvenient for non-equidistant samples. 
In the following, it is therefore only considered for regular grids as defined below.

\paragraph{Regular Nyquist grid}

In the special case of equidistant samples $x_k = x_0 + k\pi/a$, the argument of the 
sinc function in the identity for the Gramian matrix entries is equal to $a(x_j - x_k) = (j-k)\pi$. Thus, 
$\BDG_\Theta$ is diagonal, and the bi-orthogonal dictionary $\Phi$ can immediately be calculated as
%
\begin{equation*}
 \phi_j = \SINC( j\pi - a\cdot\phantom{x}\!\!).
\end{equation*}





\subsection{Re-discretization}
\label{subsec:specif:rediscr}

The transition operator from one discretization $\DISCRnX = (\SPCX, \Fn, \RnX, \EnX)$ to another one,
$\DISCR{m}{X} = (\SPCX, \Fm, \RmX, \EmX)$, is given by $\RmY \circ \EnX$ as outlined earlier. In the case of 
dictionary-based discretizations with $\Theta, \Phi$ for the first one and $\Xi, \Psi$ for the second one, this 
operator can be written as
%
\begin{equation*}
 \RmY \circ \EnX(\BDalpha) 
 = \sum_{i=1}^n \alpha_i \RmY(\phi_i)
 = \sum_{i=1}^n \alpha_i (\INNERINX{\phi_i}{\xi_j})_{j=1,\dots,m}
 = \BDG_{\Phi,\Xi} \BDalpha,
\end{equation*}
%
\ie, it is represented by the matrix
%
\begin{equation*}
 \BDG_{\Phi,\Xi} = \BDG_{\Phi,\Psi}\, \BDG_\Psi^{-\mathrm{T}}.
\end{equation*}
%
Therefore, by knowledge of the cross-Gramian matrix $\BDG_{\Phi,\Psi}$ of the known function systems it is possible 
to calculate the matrix representation of the transition operator $\RmY \circ \EnX$.


\subsubsection{Nearest neighbor to linear}
\label{subsubsec:specif:rediscr:nn2lin}

Let $\Phi$ be the piecewise constant dictionary and $\Psi$ the piecewise linear dictionary for the same nodes. It is
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\psi_i} 
 = \int_{x_i - h_{i-1}/2}^{x_i} \frac{x-x_{i-1}}{h_{i-1}}\, \D x +
 \int_{x_i}^{x_i + h_i/2} \frac{x_{i+1} - x}{h_i}\, \D x
 = \frac{3}{4}\, \bar h_i
\end{equation*}
%
and
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\psi_{i+1}} 
 = \int_{x_i}^{x_i + h_i/2} \frac{x - x_i}{h_i}\, \D x
 = \frac{1}{8}\, h_i
\end{equation*}
%
as well as $\INNERIN{L^2}{\phi_i}{\psi_{i-1}} = h_{i-1}/8$ due to symmetry. Matrix entries outside the 
three center diagonals are zero.

\paragraph{Regular grid}

Here, the transition matrix is $\BDG_{\Phi, \Psi} = h/8\cdot\TRIDIAG(1, 6, 1)$.


\subsubsection{Nearest neighbor to cubic}
\label{subsubsec:specif:rediscr:nn2cub}

Let now $\Psi$ the piecewise cubic dictionary. We calculate
%
\begin{align*}
 \INNERIN{L^2}{\phi_i}{\psi_i} 
 &= \int_{x_i - h_{i-1}/2}^{x_i} 
 \left[ -2\left( \frac{x-x_{i-1}}{h_{i-1}} \right)^3 + 3 \left( \frac{x-x_{i-1}}{h_{i-1}} \right)^2 
 \right]\, \D x + \phantom{x} \\
 &\hspace{16pt} \int_{x_i}^{x_i + h_i/2} 
 \left[ -2\left( \frac{x_{i+1}-x}{h_i} \right)^3 + 3\left( \frac{x_{i+1}-x}{h_i} \right)^2 
 \right]\, \D x \\
 &= \frac{13}{16}\, \bar h_i
\end{align*}
%
and
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\psi_{i+1}} 
 = \int_{x_i}^{x_i + h_i/2} 
 \left[ -2\left( \frac{x-x_i}{h_i} \right)^3 + 3 \left( \frac{x-x_i}{h_i} \right)^2 
 \right]\, \D x 
 = \frac{3}{32}\, h_i
\end{equation*}
%
as well as $\INNERIN{L^2}{\phi_i}{\psi_{i-1}} = 3h_{i-1}/32$ for symmetry reasons. Other matrix 
entries are again zero.

\paragraph{Regular grid}

The transition Gramian is given by $\BDG_{\Phi, \Psi} = h/32\cdot\TRIDIAG(3, 26, 3)$.

\subsubsection{Any to sinc / sinc to any}
\label{subsubsec:specif:rediscr:any2sinc}

In the sinc dictionary case, we can directly approximate the matrix elements of $\BDG_{\Phi, \Xi}$ since it is the 
dictionary $\Xi$ which is explicitly given. With the reproducing kernel property of the functions $\xi_j$, we 
can directly calculate
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\xi_j} \approx \phi_i(x_j) = \delta_{i,j}.
\end{equation*}
%
The last approximate identity is not exact since the elements of the other interpolation dictionaries are not 
bandlimited.

\paragraph{Regular Nyquist grid}

For the transition from the sinc dictionary $\Phi$ to another dictionary $\Psi$, we can calculate
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\psi_j} \approx \frac{\pi}{a}\, \psi_j(x_i) = \frac{\pi}{a}\, \delta_{i,j},
\end{equation*}
%
hence the transition matrix is approximated by ${\pi}/{a}\, \BDG_\Psi^{-\mathrm{T}}$.



\subsubsection{Linear to cubic}
\label{subsubsec:specif:rediscr:lin2cub}

For the piecewise cubic dictionary $\Psi$, we get
%
\begin{equation*}
 \INNERIN{L^2}{\phi_i}{\psi_i} = \frac{7}{10}\, \bar h_i
 \quad \text{and} \quad
 \INNERIN{L^2}{\phi_i}{\psi_{i+1}} = \frac{3}{20}\, h_i
\end{equation*}
%
and, by symmetry, $\INNERIN{L^2}{\phi_i}{\psi_{i-1}} = \frac{3}{20}\, h_{i-1}$.

\paragraph{Regular grid}

It is $\BDG_{\Phi, \Psi} = h/20\cdot\TRIDIAG(3, 14, 3)$.


\subsection{Fourier transform discretization}
\label{subsec:specif:fourier}

In general, operator discretizations have the form $\DISCOP{T} = \RmY \circ \OPT \circ \EnX$, \ie, for dictionary 
cases, one can write
%
\begin{equation*}
 \OPT\big( \EnX(\BDalpha) \big) = \sum_{j=1}^n \alpha_j \OPT(\phi_j).
\end{equation*}
%
Hence, the crucial step is to evaluate the operator in question, $\OPT$, on the dictionary $\Phi$. For the Fourier 
transform $\FT$, most examples produce a complex exponential factor $e^{-\I x_j \xi}$. Thus, the expression 
$\sum_{j=1}^n \alpha_j \FT(\phi_j)(\xi)$ takes the form of a discrete Fourier transform if $\RmX$ is the collocation 
operator at nodes $\xi_j$. 



\subsubsection{Nearest neighbor interpolation}
\label{subsubsec:specif:fourier:nn}

We get
%
\begin{align*}
 \sqrt{2\pi}\, \FT(\phi_j)(\xi)
 &= \int_{x_j - h_{j-1}/2}^{x_j + h_j/2} e^{-\I x\xi}\, \D x
 = \frac{1}{-\I\xi} e^{-\I x_j \xi} (e^{-\I h_j\xi/2} - e^{\I h_{j-1}\xi/2}) \\
 &= e^{-\I x_j \xi}\, u_j^{\mathrm{nn}}(\xi),
\end{align*}
%
with
%
\begin{equation*}
 u_j^{\mathrm{nn}}(\xi) \DEFEQ \frac{1}{\I\xi} (e^{\I h_{j-1}\xi/2} - e^{-\I h_j\xi/2}).
\end{equation*}

\paragraph{Regular grid} 

The function $u_j^{\mathrm{nn}}$ simplifies to
%
\begin{equation*}
 u_j^{\mathrm{nn}}(\xi) = \frac{2}{2\I\xi}(e^{\I h\xi/2} - e^{-\I h\xi/2}) = h\, \SINC(h\xi/2).
\end{equation*}


\subsubsection{Linear interpolation}
\label{subsubsec:specif:fourier:linear}

It is
%
\begin{align*}
 \sqrt{2\pi}\, \FT(\phi_j)(\xi)
 &= \frac{e^{-\I x_{j-1} \xi}}{h_{j-1}} \int_0^{h_{j-1}} x\, e^{-\I x\xi}\, \D x +
 \frac{e^{-\I x_{j+1} \xi}}{h_j} \int_0^{h_j} x\, e^{\I x\xi}\, \D x \\
 &= e^{-\I x_j \xi}\, u_j^{\mathrm{lin}}(\xi)
\end{align*}
%
with
%
\begin{equation*}
 u_j^{\mathrm{lin}}(\xi) \DEFEQ \frac{1 + \I h_{j-1}\xi - e^{\I h_{j-1}\xi}}{h_{j-1} \xi^2} +
 \frac{1 - \I h_j\xi - e^{-\I h_j\xi}}{h_j \xi^2}.
\end{equation*}

\paragraph{Regular grid} 

$u_j^{\mathrm{lin}}$ can be simplified to
%
\begin{equation*}
 u_j^{\mathrm{lin}}(\xi) = \frac{2\big( 1-\cos(h\xi) \big)}{h\xi^2} = h \SINC^2(h\xi/2).
\end{equation*}



\subsubsection{Cubic spline interpolation}
\label{subsubsec:specif:fourier:cubic}

We calculate
%
\begin{align*}
 \sqrt{2\pi}\, \FT(\phi_j)(\xi)
 &= \frac{-2 e^{-\I x_{j-1} \xi}}{h_{j-1}^3} \int_0^{h_{j-1}} x^3\, e^{-\I x\xi}\, \D x +
 \frac{3 e^{-\I x_{j-1} \xi}}{h_{j-1}^2} \int_0^{h_{j-1}} x^2\, e^{-\I x\xi}\, \D x + \phantom{x} \\
 &\hspace{12pt} \frac{-2 e^{-\I x_{j+1} \xi}}{h_j^3} \int_0^{h_j} x^3\, e^{-\I x\xi}\, \D x +
 \frac{3 e^{-\I x_{j+1} \xi}}{h_j^2} \int_0^{h_j} x^2\, e^{-\I x\xi}\, \D x \\
 &= e^{-\I x_j \xi}\, u_j^{\mathrm{cub}}(\xi),
\end{align*}
%
where
%
\begin{align*}
 u_j^{\mathrm{cub}}(\xi) &\DEFEQ 
 \frac{12 + 6\I h_{j-1}\xi + \I h_{j-1}^3\xi^3 + e^{\I h_{j-1}\xi} (6\I h_{j-1}\xi - 12)}{h_{j-1}^3 \xi^4} + 
 \phantom{x}\\
 &\hspace{15pt} 
 \frac{12 - 6\I h_j\xi - \I h_j^3\xi^3 + e^{-\I h_j\xi} (- 6\I h_j\xi - 12)}{h_j^3 \xi^4}.
\end{align*}

\paragraph{Regular grid} 

The function $u_j^{\mathrm{cub}}$ simplifies to
%
\begin{align*}
 u_j^{\mathrm{cub}}(\xi) 
 &= 6\, \frac{4 - 2(e^{\I h \xi} + e^{-\I h \xi}) + \I h \xi(e^{\I h \xi} - e^{-\I h \xi})}{h^3\xi^4} \\
 &= h\cdot 12\, \frac{2 - 2\cos(h\xi) - h \xi \sin(h\xi)}{(h\xi)^4} \\
\end{align*}

\subsubsection{Sinc interpolation}
\label{subsubsec:specif:fourier:sinc}

In this case, it is
%
\begin{align*}
 \FT(\phi_j)(\xi) 
 &= \sum_{k=1}^n \INNERIN{L^2}{\phi_k}{\phi_j} \FT(\theta_k)(\xi)
 = \sum_{k=1}^n \INNERIN{L^2}{\phi_k}{\phi_j} e^{\I x_k \xi}\, \sqrt{2\pi}\, \chi_{[-a,a]}(\xi)\\
 &= \sqrt{2\pi}\, \chi_{[-a,a]}(\xi)\, (\TRANSP{\BDG_\Phi} \BDF(\xi))_j,
\end{align*}
%
where $\BDF(\xi) = (e^{\I x_k \xi})_{k=1,\dots,n}$ is the vector of Fourier kernels.\\[1em]

\paragraph{Regular Nyquist grid} 

We have $\sqrt{2\pi} \FT(\phi_j)(\xi) = 2\pi \chi_{[-a,a]}(\xi)\, e^{\I x_j \xi}$ in this case since $\BDG_\Phi = \BDI$.
\todo{Check if factors are correct}



\subsection{Convolution discretization}
\label{subsec:specif:conv}

There are two ways to define a convolution on a discretized space. The first one is to apply an analytically given 
kernel to the dictionary, the second is to convolve with a discrete kernel interpreted in the same. For a closed form 
kernel, there are again two possibilities: either the convolution with the dictionary is known explicitly or it is 
reduced to the discrete case by discretizing the kernel. Since the implementation of the first case is obvious, we 
concentrate on the discrete setting where the discretization of the bi-linear convolution operator is given by
%
\begin{equation*}
 \DISCOP{C}(\BDalpha, \BDbeta) \DEFEQ \sum_{i,j=1}^n \alpha_i\, \beta_j\, \RmY(\phi_i \ast \phi_j).
\end{equation*}

If the sampling grid is regular, the interpolation dictionaries have the form 
$\phi_i(x) = \phi\big( h^{-1}(x-x_i) \big) = \phi_h(x-x_i)$, which allows to simplify the convolutions according to to
%
\begin{equation*}
 \phi_i \ast \phi_j(x) = \phi_h \ast \phi_h\big( x - (x_i + x_j) \big)
\end{equation*}
%
and
%
\begin{equation*}
 \phi_h \ast \phi_h(x) = h\, \phi \ast \phi(h^{-1} x)
\end{equation*}
%
with analogous expressions if a different function $\psi_j$ of the same structure is used as second operand instead of 
$\phi_j$.\\
%
If the subsequent restriction operator is given by the collocation at the same regular nodes $x_k$, the discretization 
$\DISCOP{C}$ of the convolution is contains the summands
%
\begin{equation*}
 h\, \phi \ast \phi\big( h^{-1}(x_k - x_i - x_j) \big) = h\, \phi( -x_0/h + k - i - j).
\end{equation*}


\subsubsection{Nearest neighbor interpolation}
\label{subsubsec:specif:conv:nn}

The convolution of two basis functions $\phi_i$ and $\phi_j$ is given by
%
\begin{align*}
 \phi_i \ast \phi_j(x) 
 &= \int_{x_j-h_{j-1}/2}^{x_j+h_j/2} \phi_i(x-y)\, \D y 
 = \int_{x-x_j-h_j/2}^{x-x_j+h_{j-1}/2} \phi_i(y)\, \D y \\
 &= \ABS[\big]{\CINTERV{x_i-h_{i-1}/2}{x_i+h_i/2} \cap \CINTERV{x-x_j-h_j/2}{x-x_j+h_{j-1}/2}}
\end{align*}
%
After tedious calculations, one can show that this intersection and thus the value of the convolution is given by
$\phi_i \ast \phi_j(x) = \phi_{i,j}\big( x - (x_i + x_j) \big)$ with
%
\begin{equation*}
 \phi_{i,j}(x) \DEFEQ
 \begin{dcases}
  \frac{h_{i-1} + h_{j-1}}{2} + x & \text{if } x \in \CINTERV*{-\frac{h_{i-1} + h_{j-1}}{2}}{m_{i,j}}, \\
  \min\SET*{\bar h_i, \bar h_j} & \text{if } x \in \CINTERV{m_{i,j}}{M_{i,j}}, \\
  \frac{h_i + h_j}{2} - x & \text{if } x \in \CINTERV*{M_{i,j}}{\frac{h_i + h_j}{2}}, \\
  0 & \text{else},
 \end{dcases}
\end{equation*}
%
where
%
\begin{equation*}
 m_{i,j} \DEFEQ \min\SET*{\frac{h_i - h_{j-1}}{2}, \frac{h_j - h_{i-1}}{2}}
 \ \ \text{and}\ \ 
 M_{i,j} \DEFEQ \max\SET*{\frac{h_i - h_{j-1}}{2}, \frac{h_j - h_{i-1}}{2}}.
\end{equation*}


\paragraph{Regular grid}

The autoconvolution of the function $\phi = \chi_{\CINTERV{-\nicefrac{1}{2}}{\nicefrac{1}{2}}}$ is given by the linear 
interpolation kernel
%
\begin{equation*}
 \phi \ast \phi(x) = 
 \begin{cases}
  1 + x & \text{if } x \in \CINTERV{-1}{0}, \\
  1 - x & \text{if } x \in \CINTERV{0}{1}, \\
  0 & \text{else.}
 \end{cases}
\end{equation*}


\subsubsection{Linear interpolation}
\label{subsubsec:specif:conv:linear}

TODO

\paragraph{Regular grid}

For the autoconvolution of the kernel corresponding linear interpolation, we get
%
\begin{align*}
 \phi \ast \phi(x) 
 &= \int_x^{x+1} \phi(y)\, (1+x-y)\, \D y + \int_{x-1}^x \phi(y)\, (1-x+y)\, \D y \\
 &= \frac{1}{6}\cdot 
 \begin{cases}
  (2+x)^3 & \text{if } x \in \CINTERV{-2}{-1} \\
  (4 - 6x^2 - 3x^3) & \text{if } x \in \CINTERV{-1}{0} \\
  (4 - 6x^2 + 3x^3) & \text{if } x \in \CINTERV{0}{1} \\
  (2-x)^3 & \text{if } x \in \CINTERV{1}{2} \\
  0 & \text{else}.
 \end{cases}
\end{align*}


\subsubsection{Cubic interpolation}
\label{subsubsec:specif:conv:cubic}

TODO

\paragraph{Regular grid}

The autoconvolution of the cubic interpolation kernel is 
%
\begin{equation*}
 \phi \ast \phi(x) = \frac{1}{70} \cdot
 \begin{cases}
  (2+x)^5 (1-6x+2x^2) & \text{if } x \in \CINTERV{-2}{-1} \\
  (52 - 84x^2 + 70x^4 + 21x^5 -14x^6 - 6x^7) & \text{if } x \in \CINTERV{-1}{0} \\
  (52 - 84x^2 + 70x^4 - 21x^5 -14x^6 + 6x^7) & \text{if } x \in \CINTERV{0}{1} \\
  (2+x)^5 (1+6x+2x^2) & \text{if } x \in \CINTERV{1}{2} \\
  0 & \text{else}.
 \end{cases}
\end{equation*}


\subsubsection{Sinc interpolation, regular Nyquist grid}
\label{subsubsec:specif:conv:sinc}

The sinc kernel autoconvolution is given by
%
\begin{equation*}
 \phi \ast \phi = \FT^{-1}\left( \sqrt{2\pi}\, \FT(\phi)^2 \right) 
 = \FT^{-1}\left( (2\pi)^{-\nicefrac{1}{2}} \chi_{\CINTERV{-1}{1}} \right) = \phi
\end{equation*}
%
since $\FT(\phi) = \FT^{-1}(\phi) = (2\pi)^{-\nicefrac{1}{2}} \chi_{\CINTERV{-1}{1}}$.



\subsection{Monomial moment operator discretization}
\label{subsec:specif:moments}

We consider the moment operators
%
\begin{equation*}
 \OPM_k \colon L^2(\RR) \supset \DOMAIN(\OPM_k) \to \FIELD
 \quad\text{with}\quad
 \OPM_k(f) \DEFEQ \int_\RR x^k\, f(x)\, \D x
\end{equation*}
%
which are defined on a dense subset of $L^2(\RR)$ (the functions which decay faster than $\ABS{x}^{-1-k}$ for 
$k \to \infty$). In this case, the operator discretization is given by
%
\begin{equation*}
 \DISCOP{M}_k(\BDalpha) \DEFEQ \OPM_k\big( \EnX(\BDalpha) \big) = \sum_{j=1}^n \alpha_j\, \OPM_k(\phi_j).
\end{equation*}
%
We give especially the formulas for the cases $k=0,1,2$ and for regular grids.


\subsubsection{Nearest neighbor interpolation}
\label{subsubsec:specif:moments:nn}

\begin{align*}
 \OPM_k(\phi_j) 
 &= \int_{x_j-h_{j-1}/2}^{x_j+h_j/2} x^k\, \D x 
 = \frac{1}{k+1}\, \left[ \left(x_j + \frac{h_j}{2}\right)^{k+1} - \left(x_j - \frac{h_{j-1}}{2}\right)^{k+1} \right], 
 \\
 \OPM_0(\phi_j) &= \frac{h_j + h_{j-1}}{2} = \bar h_j, \\
 \OPM_1(\phi_j) &= \bar h_j x_j + \frac{h_j^2 - h_{j-1}^2}{8}, \\
 \OPM_2(\phi_j) &= \bar h_j x_j^2 + x_j\, \frac{h_j^2 - h_{j-1}^2}{4} +  \frac{h_j^3 + h_{j-1}^3}{8}.
\end{align*}

\paragraph{Regular grid}

\begin{align*}
 \OPM_0(\phi_j) &= h, \\
 \OPM_1(\phi_j) &= h x_j, \\
 \OPM_2(\phi_j) &= h x_j^2 +  \frac{h^3}{4}.
\end{align*}


\subsubsection{Linear interpolation}
\label{subsubsec:specif:moments:linear}

\begin{align*}
 \OPM_k(\phi_j) 
 &= \int_{x_{j-1}}^{x_j} x^k\, \frac{x-x_{j-1}}{h_{j-1}}\, \D x + \int_{x_j}^{x_{j+1}} x^k\, \frac{x_{j+1}-x}{h_j}\, 
 \D x \\  
 &= \frac{h_{j-1} x_{j+1}^{k+2} - 2\bar h_j x_j^{k+2} + h_j x_{j-1}^{k+2}}{(k+1)(k+1) h_{j-1} h_j},
 \\
 \OPM_0(\phi_j) & = \bar h_j, \\
 \OPM_1(\phi_j) &= \bar h_j\, \frac{x_{j+1} + x_j + x_{j-1}}{3}, \\
 \OPM_2(\phi_j) &= \bar h_j\, \frac{x_{j+1}^2 + x_{j+1}x_j + x_{j+1}x_{j-1} + x_j^2 + x_jx_{j-1} + x_{j-1}^2}{6}.
\end{align*}

\paragraph{Regular grid}

\begin{align*}
 \OPM_0(\phi_j) &= h, \\
 \OPM_1(\phi_j) &= h x_j, \\
 \OPM_2(\phi_j) &= h x_j^2 +  \frac{h^3}{6}.
\end{align*}


\subsubsection{Cubic interpolation}
\label{subsubsec:specif:moments:cubic}

\begin{align*}
 \OPM_0(\phi_j) &= \bar h_j, \\
 \OPM_1(\phi_j) &= \bar h_j\, \frac{3x_{j+1} + 4x_j + 3x_{j-1}}{10}, \\
 \OPM_2(\phi_j) &= \bar h_j\, \frac{2x_{j+1}^2 + 3x_{j+1}x_j + 2x_{j+1}x_{j-1} + 3x_j^2 + 3x_jx_{j-1} + 2x_{j-1}^2}{15}.
\end{align*}

\paragraph{Regular grid}

\begin{align*}
 \OPM_0(\phi_j) &= h, \\
 \OPM_1(\phi_j) &= h x_j, \\
 \OPM_2(\phi_j) &= h x_j^2 +  \frac{2h^3}{15}.
\end{align*}


\subsubsection{Sinc interpolation, Nyquist grid}
\label{subsubsec:specif:moments:sinc}

Formally, we can calculate
%
\begin{align*}
 \int_\RR x^k\, \phi_j(x)\, \D x 
 &= h^{k+1} \int_\RR x^k\, \phi(x-j)\, \D x 
 = h^{k+1}\, \I^k\, \frac{\D^k}{\D\xi^k} \FUNCRESTR{\int_\RR \phi(x-j-x_0/h)\, e^{-\I x \xi} \D x}{\xi=0} \\
 &= h^{k+1}\, \I^k\, \frac{\D^k}{\D\xi^k} \FUNCRESTR{\Big( e^{-\I (x_0/h + j) \xi} \cdot \chi_{\CINTERV{-1}{1}}(\xi) 
 \Big)}{\xi=0}
 = h^{k+1} (x_0/h + j)^k \\
 &= h\, x_j^k
\end{align*}
%
since all derivatives of $\chi_{\CINTERV{-1}{1}}$ at $\xi=0$ vanish. However, integrability is only given in the case 
$k=0$, and only then the exchange of integration and differentiation can be justified.





\section{Software implementation}
\label{sec:soft}



\subsection{General considerations}
\label{subsec:soft:general}
%
\textbf{Discretizations:}
A discretization $\DISCRnX = (\SPCX, \Fn, \RnX, \EnX)$ is implemented as discretized linear 
space $X_n$ in the following way:
%
\begin{itemize}
 \item $X_n$ is a (or derives from) \texttt{LinearSpace}.
 \item When initialized, it is provided with \emph{instances} of $\SPCX$ and $\Fn$.
 \item It inherits the ``intersection'' of the structure of $\SPCX$ and $\Fn$, i.e. if $\SPCX$ is a 
 \texttt{MetricSpace} and $\Fn$ a \texttt{HilbertSpace}, $X_n$ will be a \texttt{MetricSpace}.
 \item Elements in $X_n$ are created by casting $n$-tuples of elements of $\FIELD$ (given as list, array, \dots).
 \item $\RnX \colon \SPCX \to \Fn$ 
   can optionally be provided as a \texttt{LinearOperator}. If $\SPCX$ is a \texttt{FunctionSpace},
   then an element $f_n \in X_n$ can be initialized from an analytically defined function $f \in \SPCX$ 
   (i.e., a Python function) as $f_n \DEFEQ  \RnX(f)$, such as in the case of point collocation.
 \item $\EnX \colon \Fn \to \SPCX$ can optionally be provided as a \texttt{LinearOperator}. 
   If $\EnX$ is given and $\SPCX$ is a \texttt{FunctionSpace}, 
   a discretized function $f_n \in X_n$ can be evaluated at any given point, e.g., by interpolation. 
   Such an interpolation rule does in this way define a continuous function $f \in \SPCX$.
\end{itemize}
%
\textbf{Re-discretizations:}
Consider two different discretizations of a fixed vector space $\SPCX$ given by 
\[ \DISCRnX = (\SPCX, \Fn, \RnX, \EnX)
   \quad\text{and}\quad
  \DISCR{\SPCX}{m} =(\SPCX, \Fm, \RmX, \EmX)
\]  
with $X_n$ and $X_m$ as the corresponding discretized linear spaces.
The re-discreti\-zation of $\DISCRnX$ into $\DISCR{\SPCX}{m}$ is the mapping 
\[  \DISCOPID_{m,n} \colon \Fm \to \Fn
    \quad\text{defined as}\quad
    \DISCOPID_{m,n} \DEFEQ  \RmX \circ \EnX.
\]   
It is represented in the software as follows:
\begin{itemize}
 \item $\DISCOPID_{m,n}$ is a \texttt{LinearOperator}\footnote{for now, may be relaxed to \texttt{Operator}} with 
 $\mathtt{domain} = X_n$ and $\mathtt{range} = X_m$.
 \item If $\EnX$ and $\RmX$ are present in $X_n$ or $X_m$, respectively, $\DISCOPID_{m,n}$ is implemented as the 
 composition of these operators by default.
 \item A direct (optimized) implementation and can be provided, e.g., by an external software package.
\end{itemize}



\subsection{Dictionary-based discretization}
\label{subsec:soft:dict}




\subsection{Examples}
\label{subsec:soft:examp}

\begin{example}[Re-interpretation]
 Let $\bar f \in X_n = (\SPCX, \Fn, \emptyset, \emptyset)$ be represented by $\BDalpha \in \Fn$ and 
 $X_m = (\SPCX, \Fm, \RmX, \EmX)$ with $m=n$. Then $\bar f$ can be re-interpreted as $\bar f \in \SPCX_m$ by 
 the identity mapping $\OPID \colon X_n \to \SPCX_m$. Practically, the re-mapped element will be aware of the ``added 
 structure '' $\RmX, \EmX$.
\end{example}





% \cleardoublepage
% \appendix
% \section{Basic definitions}
% \subsection{Algebraic structures}
% We begin with the basic definition of the underlying algebraic objects, namely ring and field.
% A field is basically an abstraction of the set $\RR$ of real numbers with the ``usual'' 
% addition and multiplication.
% \begin{definition}[Ring and field]
%   A set $\FIELD$ is a \emph{ring} if there are two laws of composition
%   $(\alpha,\beta)\mapsto \alpha+\beta$ and $(\alpha,\beta) \mapsto \alpha\cdot \beta$, called 
%   respectively \emph{addition} and \emph{multiplication}, satisfying the following axioms:
%   \begin{enumerate}
%   \item $\FIELD$ is a commutative group under addition with zero element $0_{\FIELD}$, \ie,
%     the following holds for all $\alpha,\beta,\gamma\in \FIELD$:
%     \begin{enumerate}
%     \item addition is associative, \ie, $\alpha + (\beta+\gamma)=(\alpha+\beta)+\gamma$,
%     \item addition is commutative, \ie, $\alpha + \beta = \beta+\alpha$,
%     \item the zero element is the identity element \wrt the addition so 
%        $\alpha+0_{\FIELD}=0_{\FIELD}+\alpha=\alpha$,
%     \item $-\alpha$ denotes the inverse of $\alpha$  \wrt the addition so 
%        $\alpha+(-\alpha)=(-\alpha)+\alpha=0_{\FIELD}$.
%     \end{enumerate}
%   \item the multiplication is associative and possesses an identity element $1_{\FIELD}$, \ie,
%     the following holds for all $\alpha,\beta,\gamma\in \FIELD$:
%     \begin{enumerate}
%     \item multiplication is associative, \ie, 
%       $\alpha\cdot (\beta\cdot \gamma)=(\alpha\cdot \beta)\cdot \gamma$,
%    \item $1_{\FIELD}$ is the identity element \wrt the multiplication so 
%       $1_{\FIELD}\cdot \alpha=\alpha \cdot 1_{\FIELD}=\alpha$, 
%   \end{enumerate}
%   \item the multiplication is distributive with respect to the addition, \ie,
%     for all $\alpha,\beta,\gamma\in \FIELD$,
%     \[ (\alpha+\beta)\cdot \gamma = \alpha \cdot \gamma+\beta\cdot\gamma 
%        \quad\text{and}\quad
%        \alpha \cdot (\beta + \gamma) = \alpha \cdot \beta+\alpha\cdot\gamma.
%     \]
%   \end{enumerate}
%   A ring $\FIELD$ is called a \emph{field} if it does not consist only of $0_{\FIELD}$ and every non-zero 
%   element of $\FIELD$ has an inverse \wrt the multiplication. Finally, a field is \emph{commutative}
%   if its multiplication is commutative.
% \end{definition}
% When working with fields we will simplify the notational burden by not explicitly writing 
% the multiplication $\cdot$, \ie, $\alpha \beta$ means $\alpha\cdot\beta$ whenever 
% $\alpha,\beta\in\FIELD$. Moreover, we will write $1$ and $0$ instead of $1_{\FIELD}$ and $0_{\FIELD}$.
% Having defined the concept of a field, we are now ready to define the concept of a vector 
% space.
% \begin{definition}[Vector space]
%   Let $\FIELD$ be a fixed field. Then a set $X$ is a \emph{left vector space over $\FIELD$} if 
%   $X$ is a commutative group (the group law will be written additively in what follows)
%   together with a map  $(\alpha,x) \mapsto \alpha\cdot x$, called the \emph{vector space 
%   multiplication}, where
%   \begin{enumerate}
%   \item $\alpha \cdot (x+y)=\alpha \cdot x+\alpha \cdot y$
%      for all $\alpha\in \FIELD$ and $x,y\in X$,
%   \item $(\alpha + \beta) \cdot x= \alpha \cdot x + \beta\cdot x$ 
%      for all $\alpha, \beta\in \FIELD$ and $x\in X$,\label{MII}
%   \item $\alpha \cdot (\beta \cdot x) = (\alpha\beta)\cdot x$  
%      for all $\alpha, \beta\in \FIELD$ and $x\in X$,\label{MIII}
%   \item $1\cdot x = x$ for all $x\in X$.
%   \end{enumerate}
%   If \eqref{MIII} above is replaced by the axiom
%   \[ \alpha \cdot (\beta \cdot x) = (\beta \alpha)\cdot x
%         \quad\text{for all $\alpha, \beta\in \FIELD$ and $x\in X$,}
%   \]
%   then we say that $X$ is a \emph{right vector space over $\FIELD$}. Elements in the 
%   field $\FIELD$ are called \emph{scalars} and elements in $X$ are called \emph{vectors}. 
%   Finally,  note that in \eqref{MII} above, the addition $+$ in the left hand side 
%   represents the addition in 
%   the field $\FIELD$, whereas in the right hand side it represents the group law in $X$.
% \end{definition}  
% We say that a subset $V \subset X$ is a \emph{vector subspace of $X$} if $V$ itself is a vector 
% space over $\FIELD$ with the same operations as in $X$. This is equivalent to requiring that 
% $0\in V$ and $\alpha x, x+y \in V$ whenever $x,y\in V$ and $\alpha \in \FIELD$.
% 
% Often the vector space multiplication $\cdot$ is not written explicitly. In fact, if $X$ is a 
% left (resp.\@ right) vector space over a field $\FIELD$, then any expression of the type 
% $\alpha x$ where $\alpha\in\FIELD$ and $x\in X$ means $\alpha \cdot x$. Moreover, we will not 
% notationally distinguish between the addition in $\FIELD$ and the group law in $X$, so 
% $\alpha + \beta$ refers to the addition in $\FIELD$ if $\alpha,\beta\in \FIELD$ and to the group law in 
% $X$ if $\alpha,\beta\in X$. In the same way we do not notationally distinguish between the 
% zero in $X$ and the zero in $\FIELD$
% 
% Having dealt with the notational conventions, let us now proceed by defining concepts such 
% as linear combination, basis, and dimension.
% \begin{definition}[Linear combination and independence]
%    Let $X$ be a right (resp.\@ left) vector space over a field $\FIELD$. Also, 
%    let $\{ v_1, \dots, v_{n} \}  \subset X$ be a fixed subset. An element $x\in X$ 
%    is said to be a \emph{linear combination of the elements $\{ v_1, \dots, v_{n} \}$} if 
%    there exists a subset $\{ \alpha_1,\dots,\alpha_{n} \} \subset \FIELD$ such that 
%    \[  x= \alpha_1 v_1 + \dots +  \alpha_{n} v_{n}. \]
%    The elements $\{ \alpha_1,\dots,\alpha_{n} \}$ are then called the \emph{coefficients 
%   (or coordinates)  of $x$ \wrt $\{ v_1, \dots, v_{n} \}$}. Moreover, we say that this finite 
%   set is \emph{linearly independent} if 
%    \[ \alpha_1 v_1 + \dots + \alpha_{n} v_{n} =0
%       \quad\text{implies that}\quad \alpha_1=\dots=\alpha_{n}=0. \]
%   Note that the zero in the left hand side is the zero vector in $X$ whereas the zero in the right 
%   hand side is the zero in the field $\FIELD$.
% \end{definition}
% Using the axiom of choice, one can show, see, \eg, Chapter~II, section~7 in \cite{Bo89}, 
% that every vector space $X$ has a maximal linearly independent subset $B \subset X$ 
% spanning $X$, \ie, every vector $x\in X$ can be written as a finite linear combination 
% of the elements in $B$. Such a maximal subset is called a \emph{(Hamel) basis}. If 
% $B$ denotes a basis of the vector space $X$, then any element $x\in X$ has a 
% unique representation as a linear combination of vectors $v_1,\dots,v_{n}\in B$, \ie, there 
% exists unique scalars $\alpha_1,\dots,\alpha_{n}\in\FIELD$ such that 
% \[ x = \alpha_1 v_1 + \dots + \alpha_{n} v_{n}. \]
% The scalars $\alpha_1,\dots,\alpha_{n}$ are then called the  \emph{coordinates/coefficients}
% of $x$ with respect to the basis $B$. The \emph{dimension} of $X$ is defined as the cardinality 
% of its Hamel basis. Since one can show that any two Hamel basis of $X$ 
% have the same cardinality, the concept of dimension is well-defined.
% \begin{definition}[Linear map]
%   Let $X$ and $Y$ be two (left) vector spaces over the same field $\FIELD$. A map
%   $f \colon X \to Y$ is called a \emph{linear map (homomorphism)} if
%   \[  f(x+y)=f(x)+f(y) \quad\text{and}\quad
%       f(\alpha x)=\alpha f(x)  \]
%   for all $x,y\in X$ and $\alpha\in \FIELD$.
%   Note that $\alpha x$ refers to the vector space multiplication in $X$, whereas $\alpha f(x)$
%   refers to the vector space multiplication in $Y$.
%   If $X$ and $Y$ are two (right) vector spaces over the same field $\FIELD$, then we need to
%   replace the condition $f(\alpha x)=\alpha f(x)$ with $f(x\alpha)= f(x) \alpha$.
%   Finally,  we let  $\Hom_{\FIELD}(X,Y)$ denote the set of linear mappings from $X$ into $Y$.
% \end{definition}   
% Since any result that holds for left vector spaces over $\FIELD$ also holds for right vector spaces 
% over $\FIELD$, we shall in the sequel we shall drop the prefix left (resp.\@ right). Moreover, if
% the field is commutative, then there is no difference in the sense that any left vector spaces
% is also a right vector spaces.
% 
% An important class of vector spaces are the product spaces. 
% If $X_1, \dots, \Fn$ are  vector spaces over the same field $\FIELD$, then we
% define the \emph{product space}
% \begin{equation}\label{eq:ProdSpace}
%    X\DEFEQ  X_1 \times \dots  \times \Fn 
% \end{equation}
% as the set of elements $(x_1,\dots,x_{n})$ where $x_i\in X_i$. There is a natural vector 
% space structure on $X$, namely, if $(x_1,\dots,x_{n}), (y_1,\dots,y_{n})\in X$ and 
% $\alpha\in\FIELD$, then 
% \begin{align*}
%    (x_1,\dots,x_{n})+(y_1,\dots,y_{n}) &\DEFEQ  (x_1+y_1,\dots,x_{n}+y_{n}) \\
%    \alpha (x_1,\dots,x_{n}) &\DEFEQ  (\alpha x_1,\dots,\alpha x_{n}).
% \end{align*}
% Note that $x_i+y_i$ and $\alpha x_i$ refer to the group law and vector space 
% multiplication in the vector space $X_i$. It is easy to show that with the above definitions, 
% $X$ becomes a vector space over $\FIELD$. 
% For notational simplicity, in many cases one would like to simplify the notation for
% elements in a product space $X$. 
% %In fact, we will denote such elements by the corresponding 
% %bold face letter, \ie, $(x_1,\dots,x_{n})$ is denoted 
% %by $\bx$ and $(y_1,\dots,y_{n})$ by $\by$, \etc Thus, with this notational convention 
% %$\bx_i$ refers to an element in the product space $X$ that is indexed by $i$ and 
% %$x_i$ refers to the corresponding element in $X_i$ of $\bx=(x_1,\dots,x_{n})$. 
% 
% Now, if $X$ is a product space defined as in \eqref{eq:ProdSpace}, then the 
% \emph{natural projections}
% \[ \pi_i \colon X \to X_i \quad\text{are defined as}\quad \pi_i(x)\DEFEQ x_i, \]
% and they are surjective linear mappings, \ie, $\pi_i\in\Hom_{\FIELD}(X,X_i)$. 
% Now, it is easy to show, see, \eg, Proposition~4, Section~1.5, Chapter~II in \cite{Bo89}, 
% that for any vector space $Y$ over $\FIELD$ and any finite set of linear mappings 
% $f_i \in \Hom_{\FIELD}(Y,X_i)$,  $i=1,\dots,n$, there exists a unique map 
% $f\in \Hom_{\FIELD}(Y,X)$ such that 
% \[ \pi_i \circ f = f_i. \]
% Conversely, given $f\in \Hom_{\FIELD}(Y,X)$, we can always define $f_i \in \Hom_{\FIELD}(Y,X_i)$ by 
% the above relation. 
% %We will use the bold face notation $\BDf$ on the elements in $\Hom_{\FIELD}(Y,X)$
% %\emph{only} when there is an explicit need to refer to the $f_i$:s.
% 
% We will finally define the concepts of norm and inner product for vector spaces over $\RR$ 
% or $\CC$. 
% \begin{definition}[Norm and inner product]
%   Let $\FIELD$ be a field of real numbers $\RR$ or complex numbers $\CC$  with the usual 
%   addition and multiplication. Moreover, let $X$ be a vector space over $\FIELD$. A mapping 
%   \[ \Vert \cdot \Vert \colon X \to [0,\infty[ \]
%   is called a \emph{norm on $X$} if the following holds for all $x,y \in X$ and $\alpha\in\FIELD$:
%   \begin{enumerate}
%   \item $\Vert \alpha x \Vert = \vert \alpha \vert \, \Vert x \Vert$,
%   \item $\Vert x \Vert \geq 0$ with equality if and only if $x$ is the zero element in $X$,
%   \item $\Vert x+y \Vert \leq \Vert x \Vert+\Vert y \Vert$.
%   \end{enumerate}
%   A mapping 
%   \[ \ip{\cdot}{\cdot} \colon X\times X \to \FIELD \]
%   is called the \emph{inner product on $X$}
%   if the following holds for all $x,y,z \in X$ and $\alpha\in\FIELD$:
%   \begin{enumerate}
%   \item $\ip{x}{y}=\CCONJ{\ip{y}{x}}$,
%   \item $\ip{\alpha x}{y}=\CCONJ{\alpha}\ip{x}{y}$ and $\ip{x}{\alpha  y}= \alpha \ip{x}{y}$,
%   \item $\ip{x + y}{z} = \ip{x}{z}  +  \ip{y}{z}$,
%   \item  $\ip{x}{x}\geq 0$ with equality if and only if $x$ is the zero element in $X$.
%   \end{enumerate}
%   A vector space with an inner product is called an \emph{inner product (or pre Hilbert) space}
%   and a vector space with a norm is called a \emph{normed space}.
% \end{definition}
% Let $X$ be an inner product space. Then we say that $x,y \in X$ are \emph{orthogonal} 
% if $\ip{x}{y}=0$. 
% 
% 
% \paragraph{Examples of vector spaces.}
% The first example is a trivial one, namely that any field $\FIELD$ is a one-dimensional 
% vector space over itself. The next example is the product space $\Fn$ which is  defined as 
% the $n$ fold product of $\FIELD$, \ie,
% \[ \Fn \DEFEQ  \underbrace{\FIELD \times \dots \times \FIELD}_{\text{$n$ times}}. \]
% Then $\Fn$ is an $n$-dimensional vector space 
% over $\FIELD$. In this setting, $\FIELD^1$ is isomorphic to $\FIELD$, so we will identify $\FIELD^1$ with $\FIELD$
% without further notice. The importance of the vector space $\Fn$ originates from the fact 
% that it is the canonical $n$-dimensional vector space. In fact, any $n$-dimensional vector 
% space $X$ can be naturally identified 
% with $\Fn$. Let  $\{ v_1,\dots, v_{n} \}$ be a basis of $X$ and define the map 
% $\phi \colon X \to \Fn$ as
% \[  \phi\Bigl( \sum_{i=1}^n \alpha_i v_i \Bigr) \DEFEQ  (\alpha_1,\dots,\alpha_{n})\in\Fn
%     \quad\text{so}\quad 
%     \phi^{-1}(\alpha_1,\dots,\alpha_{n}) = \sum_{i=1}^n \alpha_i v_i.
% \]
% The above map $\phi$ is an vector space isomorphism which we call the \emph{natural 
% isomorphism of $X$ \wrt the basis $\{ v_1,\dots, v_{n} \}$}, so $X$ is isomorphic to $\Fn$.
% Let us also mention that in order to comply with the notation used in 
% matrix algebra\footnote{Matrix, and more generally, tensor algebra for matrices and tensors with 
% elements in a general field $\FIELD$ is a straightforward generalization of the matrix and 
% tensor algebra for matrices and tensors with elements in $\RR$. 
% We refer to \cite[Chapter~II, Section~10 and Chapter~III]{Bo89} for the formal details.} 
% in $\FIELD$, a vector $\alpha\in\Fn$ is written as a column vector of its components, 
% \ie,
% \[ \alpha = \begin{pmatrix} \alpha_1 \\  \vdots \\  \alpha_{n} \end{pmatrix}
%    \quad\text{with $\alpha_j \in \FIELD $ for $j=1,\dots,n$.}
% \]
% 
% As a final example,  let $X$ be a set and $Y$ a vector space over a field $\FIELD$. Now, the 
% set $\Map(X,Y)$ of all mappings from $X$ into $Y$ has a natural vector space 
% structure. In fact, for $f,g\in \Map(X,Y)$ and $\alpha\in\FIELD$ we define $f+g$ and $\alpha f$ as 
% \[ (f+g)(x)\DEFEQ  f(x)+g(x) \quad\text{and}\quad (\alpha f)(x)\DEFEQ \alpha f(x) \]
% for all $x\in X$. Then, whenever $f+g, \alpha f\in  \Map(X,Y)$, the set $\Map(X,Y)$ becomes
% a vector space over $\FIELD$ under the above definitions of the group law and vector space 
% multiplication. An interesting special case is when $X$ is a vector space over $\FIELD$ and 
% $\Map(X,Y)= \Hom_{\FIELD}(X,Y)$.


%\subsection{Topological structures}
%Let $\FIELD$ denote the field of real numbers $\RR$ or complex numbers $\CC$ with the usual
%addition and multiplication. 

\bibliographystyle{plain}
\bibliography{discretization}

\end{document}
